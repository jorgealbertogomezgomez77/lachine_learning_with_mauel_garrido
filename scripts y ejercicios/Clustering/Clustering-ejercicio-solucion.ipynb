{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Clustering. Detección de Anomalías\n",
    "\n",
    "Uno de los usos de los algoritmos de clustering es la Detección de Anomalías, esto es, la detección de observaciones anómalas, aquellas que no siguen un comportamiento normal. Si el objetivo del clustering es encontrar grupos de elementos similares, aquellos elementos que no son similares a ningún grupo se pueden considerar como elementos anómalos.\n",
    "\n",
    "Para este ejercicio vamos a usar un [Dataset de transacciones de tarjetas de crédito](https://www.kaggle.com/arjunbhasin2013/ccdata), donde cada observacion es un cliente distinto.\n",
    "\n",
    "Nuestro objetivo es implementar un modelo que agrupa las transacciones apropiadamente y encontrar los potenciales outliers, es decir, aquellas transacciones que son sospechosas de ser un fraude o un error. Para resolver este ejercicio correctamente hay que investigar, en vez de simplemente seguir a rajatabla lo enseñado en el curso.\n",
    "\n",
    "**Pistas:**\n",
    "\n",
    "- Hemos explicado un algoritmo de clustering que no solo asigna elementos a clusters válidos, sino que también clasifica elementos como valores extremos (outliers). \n",
    "\n",
    "- Para la búsqueda de hiperparámetros, un buen sitio para mirar es [ParameterSampler](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterSampler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"D:/datasets/Curso_Mauel_Garrido/CC GENERAL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>BALANCE</th>\n",
       "      <th>BALANCE_FREQUENCY</th>\n",
       "      <th>PURCHASES</th>\n",
       "      <th>ONEOFF_PURCHASES</th>\n",
       "      <th>INSTALLMENTS_PURCHASES</th>\n",
       "      <th>CASH_ADVANCE</th>\n",
       "      <th>PURCHASES_FREQUENCY</th>\n",
       "      <th>ONEOFF_PURCHASES_FREQUENCY</th>\n",
       "      <th>PURCHASES_INSTALLMENTS_FREQUENCY</th>\n",
       "      <th>CASH_ADVANCE_FREQUENCY</th>\n",
       "      <th>CASH_ADVANCE_TRX</th>\n",
       "      <th>PURCHASES_TRX</th>\n",
       "      <th>CREDIT_LIMIT</th>\n",
       "      <th>PAYMENTS</th>\n",
       "      <th>MINIMUM_PAYMENTS</th>\n",
       "      <th>PRC_FULL_PAYMENT</th>\n",
       "      <th>TENURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C10001</td>\n",
       "      <td>40.900749</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>95.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>201.802084</td>\n",
       "      <td>139.509787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C10002</td>\n",
       "      <td>3202.467416</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6442.945483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>4103.032597</td>\n",
       "      <td>1072.340217</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C10003</td>\n",
       "      <td>2495.148862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>773.17</td>\n",
       "      <td>773.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>622.066742</td>\n",
       "      <td>627.284787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C10004</td>\n",
       "      <td>1666.670542</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1499.00</td>\n",
       "      <td>1499.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.788017</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C10005</td>\n",
       "      <td>817.714335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>678.334763</td>\n",
       "      <td>244.791237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CUST_ID      BALANCE  BALANCE_FREQUENCY  PURCHASES  ONEOFF_PURCHASES  \\\n",
       "0  C10001    40.900749           0.818182      95.40              0.00   \n",
       "1  C10002  3202.467416           0.909091       0.00              0.00   \n",
       "2  C10003  2495.148862           1.000000     773.17            773.17   \n",
       "3  C10004  1666.670542           0.636364    1499.00           1499.00   \n",
       "4  C10005   817.714335           1.000000      16.00             16.00   \n",
       "\n",
       "   INSTALLMENTS_PURCHASES  CASH_ADVANCE  PURCHASES_FREQUENCY  \\\n",
       "0                    95.4      0.000000             0.166667   \n",
       "1                     0.0   6442.945483             0.000000   \n",
       "2                     0.0      0.000000             1.000000   \n",
       "3                     0.0    205.788017             0.083333   \n",
       "4                     0.0      0.000000             0.083333   \n",
       "\n",
       "   ONEOFF_PURCHASES_FREQUENCY  PURCHASES_INSTALLMENTS_FREQUENCY  \\\n",
       "0                    0.000000                          0.083333   \n",
       "1                    0.000000                          0.000000   \n",
       "2                    1.000000                          0.000000   \n",
       "3                    0.083333                          0.000000   \n",
       "4                    0.083333                          0.000000   \n",
       "\n",
       "   CASH_ADVANCE_FREQUENCY  CASH_ADVANCE_TRX  PURCHASES_TRX  CREDIT_LIMIT  \\\n",
       "0                0.000000                 0              2        1000.0   \n",
       "1                0.250000                 4              0        7000.0   \n",
       "2                0.000000                 0             12        7500.0   \n",
       "3                0.083333                 1              1        7500.0   \n",
       "4                0.000000                 0              1        1200.0   \n",
       "\n",
       "      PAYMENTS  MINIMUM_PAYMENTS  PRC_FULL_PAYMENT  TENURE  \n",
       "0   201.802084        139.509787          0.000000      12  \n",
       "1  4103.032597       1072.340217          0.222222      12  \n",
       "2   622.066742        627.284787          0.000000      12  \n",
       "3     0.000000               NaN          0.000000      12  \n",
       "4   678.334763        244.791237          0.000000      12  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8950, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUST_ID                              object\n",
       "BALANCE                             float64\n",
       "BALANCE_FREQUENCY                   float64\n",
       "PURCHASES                           float64\n",
       "ONEOFF_PURCHASES                    float64\n",
       "INSTALLMENTS_PURCHASES              float64\n",
       "CASH_ADVANCE                        float64\n",
       "PURCHASES_FREQUENCY                 float64\n",
       "ONEOFF_PURCHASES_FREQUENCY          float64\n",
       "PURCHASES_INSTALLMENTS_FREQUENCY    float64\n",
       "CASH_ADVANCE_FREQUENCY              float64\n",
       "CASH_ADVANCE_TRX                      int64\n",
       "PURCHASES_TRX                         int64\n",
       "CREDIT_LIMIT                        float64\n",
       "PAYMENTS                            float64\n",
       "MINIMUM_PAYMENTS                    float64\n",
       "PRC_FULL_PAYMENT                    float64\n",
       "TENURE                                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_ids = df.CUST_ID\n",
    "df = df.drop(columns = \"CUST_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CREDIT_LIMIT', 'MINIMUM_PAYMENTS'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis = 1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputamos a 0 los valores nulos, así podemos ver si los elementos anómalos son aquellos que tienen estas columnas a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos aprendido el algoritmo DBSCAN, lo bueno de usar este algoritmo para detección de anomalías es que no asigna un cluster a todos los puntos, sino aquellos puntos que están más separados del resto se etiquetan automáticamente como valores extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al usar un algoritmo de clustering basado en densidad tenemos que estandarizar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "df_normalizado = pd.DataFrame(StandardScaler().fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1     6627\n",
       " 0     1948\n",
       " 10      60\n",
       " 2       34\n",
       " 15      30\n",
       " 7       23\n",
       " 14      23\n",
       " 8       14\n",
       " 6       13\n",
       " 3       11\n",
       " 29      10\n",
       " 21       9\n",
       " 5        9\n",
       " 9        8\n",
       " 12       8\n",
       " 1        8\n",
       " 26       8\n",
       " 17       7\n",
       " 11       7\n",
       " 27       7\n",
       " 19       7\n",
       " 4        6\n",
       " 13       6\n",
       " 23       6\n",
       " 28       5\n",
       " 30       5\n",
       " 16       5\n",
       " 24       5\n",
       " 22       5\n",
       " 25       5\n",
       " 20       5\n",
       " 18       5\n",
       " 35       5\n",
       " 31       5\n",
       " 32       4\n",
       " 34       4\n",
       " 33       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = DBSCAN()\n",
    "cluster_labels = clusterer.fit_predict(df_normalizado)\n",
    "pd.Series(cluster_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que por defecto DBSCAN produce demasiados outliers (más de 7000 elementos anómalos del total de 9000 transacciones. Podemos usar el coeficiente de silueta (`silhouette_score`) para ver como separa el algoritmo a los buenos clientes de los (potencialmente) malos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.46596190778573116"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(df_normalizado, cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un coeficiente de silueta negativo es bastante malo. Podemos hacer una búsqueda aleatoria para optimizar dicho resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'eps': 0.5,\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'euclidean',\n",
       " 'metric_params': None,\n",
       " 'min_samples': 5,\n",
       " 'n_jobs': None,\n",
       " 'p': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DBSCAN().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform \n",
    "\n",
    "\n",
    "distribucion_parametros = {\n",
    "    \"eps\": uniform(0,5),\n",
    "    \"min_samples\": sp_randint(2, 20),\n",
    "    \"p\": sp_randint(1, 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eps': <scipy.stats._distn_infrastructure.rv_frozen at 0x1bd6f8f1748>,\n",
       " 'min_samples': <scipy.stats._distn_infrastructure.rv_frozen at 0x1bd6f8f1be0>,\n",
       " 'p': <scipy.stats._distn_infrastructure.rv_frozen at 0x1bd6f8f1940>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribucion_parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un problema que hay con el algoritmo HDBSCAN (o DBSCAN) es que no tiene el método `predict`, por lo tanto no podemos usar el método de busqueda aleatoria (RandomSearchCV) de scikit-learn.\n",
    "\n",
    "Sin embargo, podemos desarrollar nuestro propio método de búsqueda con  [`ParameterSampler`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterSampler.html), que es lo que usa scikit-learn para tomar muestras del diccionario de búsqueda de hiperparámetros.\n",
    "\n",
    "**Este paso tarda tiempo en ejecutarse!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "n_muestras = 100 # probamos 20 combinaciones de hiperparámetros\n",
    "n_iteraciones = 3 #para validar, vamos a entrenar para cada selección de hiperparámetros en 3 muestras distintas\n",
    "pct_muestra = 0.7 # usamos el 70% de los datos para entrenar el modelo en cada iteracion\n",
    "resultados_busqueda = []\n",
    "lista_parametros = list(ParameterSampler(distribucion_parametros, n_iter=n_muestras))\n",
    "\n",
    "for param in lista_parametros:\n",
    "    for iteration in range(n_iteraciones):\n",
    "        param_resultados = []\n",
    "        muestra = df_normalizado.sample(frac=pct_muestra)\n",
    "        etiquetas_clusters = DBSCAN(n_jobs=-1, **param).fit_predict(muestra)\n",
    "        try:\n",
    "            param_resultados.append(silhouette_score(muestra, etiquetas_clusters))\n",
    "        except ValueError: # a veces silhouette_score falla en los casos en los que solo hay 1 cluster\n",
    "            pass\n",
    "    puntuacion_media = np.mean(param_resultados)\n",
    "    resultados_busqueda.append([puntuacion_media, param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.749018278617725, {'eps': 4.745213366201398, 'min_samples': 10, 'p': 1}],\n",
       " [0.741716474106214, {'eps': 4.981698293453857, 'min_samples': 14, 'p': 2}],\n",
       " [0.7416284232855861, {'eps': 4.782283682818845, 'min_samples': 13, 'p': 2}],\n",
       " [0.7335724628139673, {'eps': 4.673557587098347, 'min_samples': 5, 'p': 2}],\n",
       " [0.7327615465034267, {'eps': 4.678605084801343, 'min_samples': 9, 'p': 2}]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(resultados_busqueda, key=lambda x: x[0], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejores_params = {'eps': 4.745213366201398, 'min_samples':10, 'p': 1}\n",
    "\n",
    "clusterer = DBSCAN(n_jobs=-1, **mejores_params)\n",
    "\n",
    "etiquetas_cluster = clusterer.fit_predict(df_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    8879\n",
       "-1      71\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(etiquetas_cluster).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay 60 anomalias potenciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumen_cluster(cluster_id):\n",
    "    cluster = df[etiquetas_cluster == cluster_id]\n",
    "    resumen_cluster = cluster.mean().to_dict()\n",
    "    resumen_cluster[\"cluster_id\"] = cluster_id\n",
    "    return resumen_cluster\n",
    "\n",
    "def comparar_clusters(*cluster_ids):\n",
    "    resumenes = []\n",
    "    for cluster_id in cluster_ids:\n",
    "        resumenes.append(resumen_cluster(cluster_id))\n",
    "    return pd.DataFrame(resumenes).set_index(\"cluster_id\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cluster_id</th>\n",
       "      <th>0</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BALANCE</th>\n",
       "      <td>1526.628065</td>\n",
       "      <td>6297.452338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALANCE_FREQUENCY</th>\n",
       "      <td>0.876657</td>\n",
       "      <td>0.954076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASH_ADVANCE</th>\n",
       "      <td>932.764611</td>\n",
       "      <td>6744.781376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASH_ADVANCE_FREQUENCY</th>\n",
       "      <td>0.133753</td>\n",
       "      <td>0.309091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASH_ADVANCE_TRX</th>\n",
       "      <td>3.119833</td>\n",
       "      <td>19.380282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREDIT_LIMIT</th>\n",
       "      <td>4423.147667</td>\n",
       "      <td>13347.887324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTALLMENTS_PURCHASES</th>\n",
       "      <td>380.104829</td>\n",
       "      <td>4283.163944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MINIMUM_PAYMENTS</th>\n",
       "      <td>774.430432</td>\n",
       "      <td>8281.466145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONEOFF_PURCHASES</th>\n",
       "      <td>527.734622</td>\n",
       "      <td>8683.926197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONEOFF_PURCHASES_FREQUENCY</th>\n",
       "      <td>0.200019</td>\n",
       "      <td>0.507387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENTS</th>\n",
       "      <td>1597.012173</td>\n",
       "      <td>18757.273104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRC_FULL_PAYMENT</th>\n",
       "      <td>0.152836</td>\n",
       "      <td>0.263533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASES</th>\n",
       "      <td>907.536869</td>\n",
       "      <td>12967.090141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASES_FREQUENCY</th>\n",
       "      <td>0.488426</td>\n",
       "      <td>0.731029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASES_INSTALLMENTS_FREQUENCY</th>\n",
       "      <td>0.362481</td>\n",
       "      <td>0.609042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASES_TRX</th>\n",
       "      <td>14.119608</td>\n",
       "      <td>88.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TENURE</th>\n",
       "      <td>11.516500</td>\n",
       "      <td>11.619718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cluster_id                                  0            -1\n",
       "BALANCE                           1526.628065   6297.452338\n",
       "BALANCE_FREQUENCY                    0.876657      0.954076\n",
       "CASH_ADVANCE                       932.764611   6744.781376\n",
       "CASH_ADVANCE_FREQUENCY               0.133753      0.309091\n",
       "CASH_ADVANCE_TRX                     3.119833     19.380282\n",
       "CREDIT_LIMIT                      4423.147667  13347.887324\n",
       "INSTALLMENTS_PURCHASES             380.104829   4283.163944\n",
       "MINIMUM_PAYMENTS                   774.430432   8281.466145\n",
       "ONEOFF_PURCHASES                   527.734622   8683.926197\n",
       "ONEOFF_PURCHASES_FREQUENCY           0.200019      0.507387\n",
       "PAYMENTS                          1597.012173  18757.273104\n",
       "PRC_FULL_PAYMENT                     0.152836      0.263533\n",
       "PURCHASES                          907.536869  12967.090141\n",
       "PURCHASES_FREQUENCY                  0.488426      0.731029\n",
       "PURCHASES_INSTALLMENTS_FREQUENCY     0.362481      0.609042\n",
       "PURCHASES_TRX                       14.119608     88.521127\n",
       "TENURE                              11.516500     11.619718"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparar_clusters(0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
