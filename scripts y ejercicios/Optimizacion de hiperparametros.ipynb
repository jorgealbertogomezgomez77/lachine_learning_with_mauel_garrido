{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-08T17:01:38-05:00\n",
      "\n",
      "CPython 3.7.3rc1\n",
      "IPython 7.3.0\n",
      "\n",
      "compiler   : MSC v.1916 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [12, 8]\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de hiperparámetros\n",
    "\n",
    "Hasta ahora hemos visto una manera relativamente sencilla de ver que valores de los hiperparámetros funcionan mejor, mediante las curvas de validación.\n",
    "\n",
    "Estas curvas son muy útiles para darnos información a los Data Scientists, pero tienen dos problemas:\n",
    "- Son métodos gráficos, esto significa que necesitan un humano para interpretarlas y no nos permiten automatizar el proceso para encontrar los hiperparámetros óptimos.\n",
    "- Solo toman un hiperparámetro a la vez. Esto significa que hacen que sea más dificil el evaluar combinaciones de los hiperparámetros (si quisieramos evaluar multiples hiperparámetros tendriamos que hacer gráficas de planos o hiperplanos).\n",
    "\n",
    "Vamos a ver ahora métodos más robustos para dado un modelo, encontrar el conjunto de hiperparámetros que hace que funcione mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos los datos\n",
    "\n",
    "Vamos a usar un dataset nuevo, el [Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income). Es un dataset que tiene datos demográficos sobre 50,000 personas en Estados Unidos y como variable objetivo tiene una variable booleana (Verdadero/Falso) sobre si dicha persona gana más de 50K$ al año o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "censo = pd.read_csv(\"D:/datasets/Curso_Mauel_Garrido/salario_censo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>clase_laboral</th>\n",
       "      <th>nivel_educativo</th>\n",
       "      <th>status_matrimonial</th>\n",
       "      <th>ocupacion</th>\n",
       "      <th>relacion</th>\n",
       "      <th>raza</th>\n",
       "      <th>genero</th>\n",
       "      <th>ganancias_capital</th>\n",
       "      <th>perdidas_capital</th>\n",
       "      <th>horas_laborables</th>\n",
       "      <th>pais_origen</th>\n",
       "      <th>objetivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edad      clase_laboral  nivel_educativo   status_matrimonial  \\\n",
       "0    39          State-gov               13        Never-married   \n",
       "1    50   Self-emp-not-inc               13   Married-civ-spouse   \n",
       "2    38            Private                9             Divorced   \n",
       "3    53            Private                7   Married-civ-spouse   \n",
       "4    28            Private               13   Married-civ-spouse   \n",
       "\n",
       "            ocupacion        relacion    raza   genero  ganancias_capital  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male               2174   \n",
       "1     Exec-managerial         Husband   White     Male                  0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male                  0   \n",
       "3   Handlers-cleaners         Husband   Black     Male                  0   \n",
       "4      Prof-specialty            Wife   Black   Female                  0   \n",
       "\n",
       "   perdidas_capital  horas_laborables     pais_origen objetivo  \n",
       "0                 0                40   United-States    <=50K  \n",
       "1                 0                13   United-States    <=50K  \n",
       "2                 0                40   United-States    <=50K  \n",
       "3                 0                40   United-States    <=50K  \n",
       "4                 0                40            Cuba    <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline de procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dependiente = \"objetivo\"\n",
    "variables_independientes = censo.drop(variable_dependiente, axis=1).columns\n",
    "censo_X = censo[variables_independientes]\n",
    "censo_y = censo[variable_dependiente]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censo_y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso la variable objetivo está definida como texto, asi que la convertimos a una variable binaria numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "censo_y = censo_y.replace({\" <=50K\": 0, \" >50K\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos datos en numéricos y no numéricos. Viendo el [diccionario de datos](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names) del dataset vemos que no hay variables categóricas, solo la variable educacion que ya viene codificada como numérica (*education-num*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_numericos = censo_X.select_dtypes(np.number)\n",
    "col_numericas = datos_numericos.columns\n",
    "\n",
    "datos_categoricos = censo_X.select_dtypes([object])\n",
    "col_no_numericas = datos_categoricos.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar un transformador nuevo `MultiLabelBinarizer`. Es como el LabelBinarizer pero funciona para multiples columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = MultiLabelBinarizer()\n",
    "b.fit_transform(\n",
    " [\n",
    "     [\"gato\", \"patata\", \"rojo\"],\n",
    "     [\"perro\", \"zanahoria\", \"azul\"],\n",
    "     [\"camello\", \"patata\", \"verde\"],\n",
    "     [\"gato\", \"patata\", \"rojo\"]\n",
    " ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `classes_` podemos ver los diferentes valores de las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['azul', 'camello', 'gato', 'patata', 'perro', 'rojo', 'verde',\n",
       "       'zanahoria'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el transformador `BinarizadorMultipleCategorico` que es básicamente el MultiLabelBinarizer pero \"arreglado\" para que funcione en Pipelines (Estoy usando sklearn 0.19.0, este bug se arreglará en el futuro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class ColumnExtractor(TransformerMixin):\n",
    "    \"\"\"Transformador que selecciona columnas de un dataframe\"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.columns].as_matrix()\n",
    "        \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "class BinarizadorMultipleCategorico(preprocessing.MultiLabelBinarizer):\n",
    "    def fit(self, X, y = None):\n",
    "        super(BinarizadorMultipleCategorico, self).fit(X)\n",
    "        \n",
    "    def transform(self, X, y= None):\n",
    "        return super(BinarizadorMultipleCategorico, self).transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y = None):\n",
    "        return super(BinarizadorMultipleCategorico, self).fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "pipeline_numerico = Pipeline([\n",
    "    ('selector_numerico', ColumnExtractor(columns = col_numericas)),\n",
    "    ('imputador', Imputer()),\n",
    "    ('escalador', StandardScaler()),\n",
    "])\n",
    "\n",
    "pipeline_categorico = Pipeline([\n",
    "    ('selector_categorico', ColumnExtractor(columns = col_no_numericas)),\n",
    "    ('codificador_numerico', BinarizadorMultipleCategorico()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32561, 84)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_categorico.fit_transform(censo_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['edad', 'nivel_educativo', 'ganancias_capital', 'perdidas_capital',\n",
       "       'horas_laborables'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32561, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_numerico.fit_transform(censo_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_procesado = FeatureUnion([\n",
    "    ('transformacion_numericas', pipeline_numerico),\n",
    "    ('transformacion_categorica', pipeline_categorico),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('transformacion_numericas', Pipeline(memory=None,\n",
       "     steps=[('selector_numerico', <__main__.ColumnExtractor object at 0x000002C3BC5BD1D0>), ('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('escalador', StandardScaler(copy=True, with_m...98>), ('codificador_numerico', BinarizadorMultipleCategorico(classes=None, sparse_output=False))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "censo_X_procesado = pipeline_procesado.fit_transform(censo_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 89)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censo_X_procesado.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes que nada vamos a ver que puntuaciones tienen unos cuantos modelos con sus  hiperparámetro por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def evaluar_modelo(estimador, X, y):\n",
    "    resultados_estimador = cross_validate(estimador, X, y,\n",
    "                     scoring=\"roc_auc\", n_jobs=-1, cv=5, return_train_score=True)\n",
    "    return resultados_estimador\n",
    "\n",
    "def ver_resultados():\n",
    "    resultados_df  = pd.DataFrame(resultados).T\n",
    "    resultados_cols = resultados_df.columns\n",
    "    for col in resultados_df:\n",
    "        resultados_df[col] = resultados_df[col].apply(np.mean)\n",
    "        resultados_df[col+\"_idx\"] = resultados_df[col] / resultados_df[col].max()\n",
    "    return resultados_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"reg_logistica\"] = evaluar_modelo(LogisticRegression(), censo_X_procesado, censo_y)\n",
    "resultados[\"naive_bayes\"] = evaluar_modelo(GaussianNB(), censo_X_procesado, censo_y)\n",
    "resultados[\"rf\"] = evaluar_modelo(RandomForestClassifier(), censo_X_procesado, censo_y)\n",
    "resultados[\"svc\"] = evaluar_modelo(SVC(), censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>fit_time_idx</th>\n",
       "      <th>score_time_idx</th>\n",
       "      <th>test_score_idx</th>\n",
       "      <th>train_score_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.843554</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.906715</td>\n",
       "      <td>0.908326</td>\n",
       "      <td>0.010787</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.997895</td>\n",
       "      <td>0.912449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.218701</td>\n",
       "      <td>0.043737</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.783341</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.859760</td>\n",
       "      <td>0.786896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.731085</td>\n",
       "      <td>0.028119</td>\n",
       "      <td>0.874262</td>\n",
       "      <td>0.995482</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.962178</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>78.197806</td>\n",
       "      <td>11.003671</td>\n",
       "      <td>0.908628</td>\n",
       "      <td>0.910540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fit_time  score_time  test_score  train_score  fit_time_idx  \\\n",
       "reg_logistica   0.843554    0.018744    0.906715     0.908326      0.010787   \n",
       "naive_bayes     0.218701    0.043737    0.781202     0.783341      0.002797   \n",
       "rf              0.731085    0.028119    0.874262     0.995482      0.009349   \n",
       "svc            78.197806   11.003671    0.908628     0.910540      1.000000   \n",
       "\n",
       "               score_time_idx  test_score_idx  train_score_idx  \n",
       "reg_logistica        0.001703        0.997895         0.912449  \n",
       "naive_bayes          0.003975        0.859760         0.786896  \n",
       "rf                   0.002555        0.962178         1.000000  \n",
       "svc                  1.000000        1.000000         0.914673  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_resultados()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a seleccionar un estimador en función de los resultados iniciales y optimizarlo. Elijo el estimador Random Forest por que funciona muy bien en comparación a los demás y es bastánte rápido de entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimador_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn tiene dos métodos de optimización de hiperparámetros, [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) y [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV).\n",
    "\n",
    "`GridSearchCV` funciona realizando una busqueda en una malla, es decir, pasandole un conjunto de posibles opciones de hiperparámetros evalua de forma completa cada combinación de dichos parámetros (es decir, el valor 1 del hiperparámetro 1 combinado con todos los posibles valores de los demás hiperparámetros, el valor 2 del hiperparámetro 1 combinado con todos los posibles valores de los demás hiperparámetros, etcétera).\n",
    "\n",
    "La ventaja de utilizar una búsqueda de malla es que nos aseguramos de que se han probado todas las combinaciones posibles. El problema es que el proceso requiere mucho tiempo de computación, y según que dataset usemos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 ns ± 11.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import time\n",
    "def foo():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 ns ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1  #n 1 dice que ejecute esta celda solo una vez, -r 1 que ejecute un solo loop\n",
    "def foo():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random forest classifier.\n",
      "\n",
      "    A random forest is a meta estimator that fits a number of decision tree\n",
      "    classifiers on various sub-samples of the dataset and uses averaging to\n",
      "    improve the predictive accuracy and control over-fitting.\n",
      "    The sub-sample size is always the same as the original\n",
      "    input sample size but the samples are drawn with replacement if\n",
      "    `bootstrap=True` (default).\n",
      "\n",
      "    Read more in the :ref:`User Guide <forest>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n_estimators : integer, optional (default=10)\n",
      "        The number of trees in the forest.\n",
      "\n",
      "        .. versionchanged:: 0.20\n",
      "           The default value of ``n_estimators`` will change from 10 in\n",
      "           version 0.20 to 100 in version 0.22.\n",
      "\n",
      "    criterion : string, optional (default=\"gini\")\n",
      "        The function to measure the quality of a split. Supported criteria are\n",
      "        \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      "        Note: this parameter is tree-specific.\n",
      "\n",
      "    max_depth : integer or None, optional (default=None)\n",
      "        The maximum depth of the tree. If None, then nodes are expanded until\n",
      "        all leaves are pure or until all leaves contain less than\n",
      "        min_samples_split samples.\n",
      "\n",
      "    min_samples_split : int, float, optional (default=2)\n",
      "        The minimum number of samples required to split an internal node:\n",
      "\n",
      "        - If int, then consider `min_samples_split` as the minimum number.\n",
      "        - If float, then `min_samples_split` is a fraction and\n",
      "          `ceil(min_samples_split * n_samples)` are the minimum\n",
      "          number of samples for each split.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_samples_leaf : int, float, optional (default=1)\n",
      "        The minimum number of samples required to be at a leaf node.\n",
      "        A split point at any depth will only be considered if it leaves at\n",
      "        least ``min_samples_leaf`` training samples in each of the left and\n",
      "        right branches.  This may have the effect of smoothing the model,\n",
      "        especially in regression.\n",
      "\n",
      "        - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "        - If float, then `min_samples_leaf` is a fraction and\n",
      "          `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "          number of samples for each node.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_weight_fraction_leaf : float, optional (default=0.)\n",
      "        The minimum weighted fraction of the sum total of weights (of all\n",
      "        the input samples) required to be at a leaf node. Samples have\n",
      "        equal weight when sample_weight is not provided.\n",
      "\n",
      "    max_features : int, float, string or None, optional (default=\"auto\")\n",
      "        The number of features to consider when looking for the best split:\n",
      "\n",
      "        - If int, then consider `max_features` features at each split.\n",
      "        - If float, then `max_features` is a fraction and\n",
      "          `int(max_features * n_features)` features are considered at each\n",
      "          split.\n",
      "        - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      "        - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
      "        - If \"log2\", then `max_features=log2(n_features)`.\n",
      "        - If None, then `max_features=n_features`.\n",
      "\n",
      "        Note: the search for a split does not stop until at least one\n",
      "        valid partition of the node samples is found, even if it requires to\n",
      "        effectively inspect more than ``max_features`` features.\n",
      "\n",
      "    max_leaf_nodes : int or None, optional (default=None)\n",
      "        Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      "        Best nodes are defined as relative reduction in impurity.\n",
      "        If None then unlimited number of leaf nodes.\n",
      "\n",
      "    min_impurity_decrease : float, optional (default=0.)\n",
      "        A node will be split if this split induces a decrease of the impurity\n",
      "        greater than or equal to this value.\n",
      "\n",
      "        The weighted impurity decrease equation is the following::\n",
      "\n",
      "            N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                                - N_t_L / N_t * left_impurity)\n",
      "\n",
      "        where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "        samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "        left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "        if ``sample_weight`` is passed.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "\n",
      "    min_impurity_split : float, (default=1e-7)\n",
      "        Threshold for early stopping in tree growth. A node will split\n",
      "        if its impurity is above the threshold, otherwise it is a leaf.\n",
      "\n",
      "        .. deprecated:: 0.19\n",
      "           ``min_impurity_split`` has been deprecated in favor of\n",
      "           ``min_impurity_decrease`` in 0.19. The default value of\n",
      "           ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      "           will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      "\n",
      "\n",
      "    bootstrap : boolean, optional (default=True)\n",
      "        Whether bootstrap samples are used when building trees. If False, the\n",
      "        whole datset is used to build each tree.\n",
      "\n",
      "    oob_score : bool (default=False)\n",
      "        Whether to use out-of-bag samples to estimate\n",
      "        the generalization accuracy.\n",
      "\n",
      "    n_jobs : int or None, optional (default=None)\n",
      "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
      "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "        for more details.\n",
      "\n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "\n",
      "    verbose : int, optional (default=0)\n",
      "        Controls the verbosity when fitting and predicting.\n",
      "\n",
      "    warm_start : bool, optional (default=False)\n",
      "        When set to ``True``, reuse the solution of the previous call to fit\n",
      "        and add more estimators to the ensemble, otherwise, just fit a whole\n",
      "        new forest. See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "    class_weight : dict, list of dicts, \"balanced\", \"balanced_subsample\" or     None, optional (default=None)\n",
      "        Weights associated with classes in the form ``{class_label: weight}``.\n",
      "        If not given, all classes are supposed to have weight one. For\n",
      "        multi-output problems, a list of dicts can be provided in the same\n",
      "        order as the columns of y.\n",
      "\n",
      "        Note that for multioutput (including multilabel) weights should be\n",
      "        defined for each class of every column in its own dict. For example,\n",
      "        for four-class multilabel classification weights should be\n",
      "        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      "        [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      "\n",
      "        The \"balanced\" mode uses the values of y to automatically adjust\n",
      "        weights inversely proportional to class frequencies in the input data\n",
      "        as ``n_samples / (n_classes * np.bincount(y))``\n",
      "\n",
      "        The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      "        weights are computed based on the bootstrap sample for every tree\n",
      "        grown.\n",
      "\n",
      "        For multi-output, the weights of each column of y will be multiplied.\n",
      "\n",
      "        Note that these weights will be multiplied with sample_weight (passed\n",
      "        through the fit method) if sample_weight is specified.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    estimators_ : list of DecisionTreeClassifier\n",
      "        The collection of fitted sub-estimators.\n",
      "\n",
      "    classes_ : array of shape = [n_classes] or a list of such arrays\n",
      "        The classes labels (single output problem), or a list of arrays of\n",
      "        class labels (multi-output problem).\n",
      "\n",
      "    n_classes_ : int or list\n",
      "        The number of classes (single output problem), or a list containing the\n",
      "        number of classes for each output (multi-output problem).\n",
      "\n",
      "    n_features_ : int\n",
      "        The number of features when ``fit`` is performed.\n",
      "\n",
      "    n_outputs_ : int\n",
      "        The number of outputs when ``fit`` is performed.\n",
      "\n",
      "    feature_importances_ : array of shape = [n_features]\n",
      "        The feature importances (the higher, the more important the feature).\n",
      "\n",
      "    oob_score_ : float\n",
      "        Score of the training dataset obtained using an out-of-bag estimate.\n",
      "\n",
      "    oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
      "        Decision function computed with out-of-bag estimate on the training\n",
      "        set. If n_estimators is small it might be possible that a data point\n",
      "        was never left out during the bootstrap. In this case,\n",
      "        `oob_decision_function_` might contain NaN.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.ensemble import RandomForestClassifier\n",
      "    >>> from sklearn.datasets import make_classification\n",
      "\n",
      "    >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      "    ...                            n_informative=2, n_redundant=0,\n",
      "    ...                            random_state=0, shuffle=False)\n",
      "    >>> clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
      "    ...                              random_state=0)\n",
      "    >>> clf.fit(X, y)\n",
      "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                min_samples_leaf=1, min_samples_split=2,\n",
      "                min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "                oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "    >>> print(clf.feature_importances_)\n",
      "    [0.14205973 0.76664038 0.0282433  0.06305659]\n",
      "    >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      "    [1]\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The default values for the parameters controlling the size of the trees\n",
      "    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "    unpruned trees which can potentially be very large on some data sets. To\n",
      "    reduce memory consumption, the complexity and size of the trees should be\n",
      "    controlled by setting those parameter values.\n",
      "\n",
      "    The features are always randomly permuted at each split. Therefore,\n",
      "    the best found split may vary, even with the same training data,\n",
      "    ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      "    of the criterion is identical for several splits enumerated during the\n",
      "    search of the best split. To obtain a deterministic behaviour during\n",
      "    fitting, ``random_state`` has to be fixed.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "\n",
      "    .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    DecisionTreeClassifier, ExtraTreesClassifier\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(estimador_rf.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimador_rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir los límites de la búsqueda de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10,  120,  230,  340,  450,  560,  670,  780,  890, 1000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(10,1000,10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_busqueda_rf = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": np.linspace(10,1000,10).astype(int),\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator = estimador_rf, \n",
    "                    param_grid = parametros_busqueda_rf,\n",
    "                    scoring = \"roc_auc\", n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` se comporta como un estimador en cuanto a que tiene un metodo fit que usamos para \"entrenarlo\" y que realize la búsqueda en malla.\n",
    "\n",
    "Para ver cuanto tiempo tarda en realizar la búsqueda usamos la mágia de Jupyter notebook `%%timeit` que evalua el tiempo que tarda una función en ejecutarse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17min 54s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "grid.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi ordenador la busqueda en malla ha tardado 7minutos y 49 segundos \n",
    "\n",
    "Ahora podemos ver la puntuación que ha obtenido el mejor estimador así como los parámetros del mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8973722564825424\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=780, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras haberlo ajustado, Gridsearch nos devuelve el ranking de todas las variantes evaluadas junto con métricas de su funcionamiento con el atributo `cv_results_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46.176672</td>\n",
       "      <td>0.743398</td>\n",
       "      <td>3.342973</td>\n",
       "      <td>2.551143e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894313</td>\n",
       "      <td>0.896849</td>\n",
       "      <td>0.900955</td>\n",
       "      <td>0.897372</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998242</td>\n",
       "      <td>0.998151</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>0.998144</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38.157726</td>\n",
       "      <td>1.052273</td>\n",
       "      <td>3.103431</td>\n",
       "      <td>3.437397e-01</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894590</td>\n",
       "      <td>0.896329</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.897154</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998217</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>0.998036</td>\n",
       "      <td>0.998128</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>56.528426</td>\n",
       "      <td>0.174090</td>\n",
       "      <td>4.426032</td>\n",
       "      <td>4.101676e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894219</td>\n",
       "      <td>0.896328</td>\n",
       "      <td>0.900782</td>\n",
       "      <td>0.897109</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998142</td>\n",
       "      <td>0.998037</td>\n",
       "      <td>0.998129</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50.878694</td>\n",
       "      <td>0.121674</td>\n",
       "      <td>3.780363</td>\n",
       "      <td>3.374661e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894154</td>\n",
       "      <td>0.896449</td>\n",
       "      <td>0.900382</td>\n",
       "      <td>0.896995</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>0.998145</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998139</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31.305159</td>\n",
       "      <td>0.091977</td>\n",
       "      <td>2.317168</td>\n",
       "      <td>1.947881e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894229</td>\n",
       "      <td>0.896100</td>\n",
       "      <td>0.900372</td>\n",
       "      <td>0.896900</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998212</td>\n",
       "      <td>0.998136</td>\n",
       "      <td>0.998026</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42.073466</td>\n",
       "      <td>0.162007</td>\n",
       "      <td>3.369003</td>\n",
       "      <td>5.154582e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893878</td>\n",
       "      <td>0.896152</td>\n",
       "      <td>0.900261</td>\n",
       "      <td>0.896764</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>6</td>\n",
       "      <td>0.998223</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>0.998034</td>\n",
       "      <td>0.998136</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.197209</td>\n",
       "      <td>0.045978</td>\n",
       "      <td>1.843321</td>\n",
       "      <td>1.275893e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.893480</td>\n",
       "      <td>0.896597</td>\n",
       "      <td>0.900106</td>\n",
       "      <td>0.896728</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998230</td>\n",
       "      <td>0.998146</td>\n",
       "      <td>0.998023</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.454998</td>\n",
       "      <td>0.250044</td>\n",
       "      <td>2.889946</td>\n",
       "      <td>3.375194e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893930</td>\n",
       "      <td>0.895824</td>\n",
       "      <td>0.900354</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998234</td>\n",
       "      <td>0.998134</td>\n",
       "      <td>0.998039</td>\n",
       "      <td>0.998136</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48.561528</td>\n",
       "      <td>0.269463</td>\n",
       "      <td>3.874090</td>\n",
       "      <td>2.209057e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893569</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.896684</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>9</td>\n",
       "      <td>0.998225</td>\n",
       "      <td>0.998151</td>\n",
       "      <td>0.998028</td>\n",
       "      <td>0.998134</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54.768409</td>\n",
       "      <td>0.413499</td>\n",
       "      <td>4.353146</td>\n",
       "      <td>9.573045e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893440</td>\n",
       "      <td>0.896140</td>\n",
       "      <td>0.900286</td>\n",
       "      <td>0.896622</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>10</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>0.998152</td>\n",
       "      <td>0.998041</td>\n",
       "      <td>0.998138</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44.067790</td>\n",
       "      <td>0.071017</td>\n",
       "      <td>3.322138</td>\n",
       "      <td>6.419739e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.894058</td>\n",
       "      <td>0.895783</td>\n",
       "      <td>0.899849</td>\n",
       "      <td>0.896563</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>11</td>\n",
       "      <td>0.997588</td>\n",
       "      <td>0.997571</td>\n",
       "      <td>0.997063</td>\n",
       "      <td>0.997407</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>49.342595</td>\n",
       "      <td>4.641310</td>\n",
       "      <td>3.145095</td>\n",
       "      <td>3.326839e-01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893959</td>\n",
       "      <td>0.895902</td>\n",
       "      <td>0.899687</td>\n",
       "      <td>0.896516</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>12</td>\n",
       "      <td>0.997608</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997090</td>\n",
       "      <td>0.997423</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.792457</td>\n",
       "      <td>0.046005</td>\n",
       "      <td>1.379887</td>\n",
       "      <td>7.360526e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.893714</td>\n",
       "      <td>0.896183</td>\n",
       "      <td>0.899635</td>\n",
       "      <td>0.896510</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>13</td>\n",
       "      <td>0.998188</td>\n",
       "      <td>0.998109</td>\n",
       "      <td>0.998008</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.827745</td>\n",
       "      <td>0.157425</td>\n",
       "      <td>1.884976</td>\n",
       "      <td>2.655175e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893501</td>\n",
       "      <td>0.895707</td>\n",
       "      <td>0.900139</td>\n",
       "      <td>0.896449</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>14</td>\n",
       "      <td>0.998246</td>\n",
       "      <td>0.998128</td>\n",
       "      <td>0.998020</td>\n",
       "      <td>0.998132</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>50.566250</td>\n",
       "      <td>0.409157</td>\n",
       "      <td>3.837642</td>\n",
       "      <td>6.027848e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.894034</td>\n",
       "      <td>0.896016</td>\n",
       "      <td>0.899165</td>\n",
       "      <td>0.896405</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>15</td>\n",
       "      <td>0.997621</td>\n",
       "      <td>0.997558</td>\n",
       "      <td>0.997075</td>\n",
       "      <td>0.997418</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>25.285750</td>\n",
       "      <td>0.099085</td>\n",
       "      <td>1.890169</td>\n",
       "      <td>2.551027e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893945</td>\n",
       "      <td>0.896013</td>\n",
       "      <td>0.899087</td>\n",
       "      <td>0.896348</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>16</td>\n",
       "      <td>0.997609</td>\n",
       "      <td>0.997542</td>\n",
       "      <td>0.997014</td>\n",
       "      <td>0.997389</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.529297</td>\n",
       "      <td>0.153234</td>\n",
       "      <td>2.374445</td>\n",
       "      <td>1.275396e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893302</td>\n",
       "      <td>0.895537</td>\n",
       "      <td>0.899831</td>\n",
       "      <td>0.896223</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>17</td>\n",
       "      <td>0.998240</td>\n",
       "      <td>0.998145</td>\n",
       "      <td>0.998042</td>\n",
       "      <td>0.998142</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.855707</td>\n",
       "      <td>0.197733</td>\n",
       "      <td>2.822254</td>\n",
       "      <td>3.682084e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893615</td>\n",
       "      <td>0.895562</td>\n",
       "      <td>0.899296</td>\n",
       "      <td>0.896158</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>18</td>\n",
       "      <td>0.997590</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.997072</td>\n",
       "      <td>0.997399</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>31.976866</td>\n",
       "      <td>0.079664</td>\n",
       "      <td>2.337994</td>\n",
       "      <td>1.948317e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893350</td>\n",
       "      <td>0.896074</td>\n",
       "      <td>0.898938</td>\n",
       "      <td>0.896120</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>19</td>\n",
       "      <td>0.997592</td>\n",
       "      <td>0.997583</td>\n",
       "      <td>0.997028</td>\n",
       "      <td>0.997401</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>55.049591</td>\n",
       "      <td>0.630426</td>\n",
       "      <td>4.405221</td>\n",
       "      <td>1.470921e-01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.893357</td>\n",
       "      <td>0.895588</td>\n",
       "      <td>0.899280</td>\n",
       "      <td>0.896075</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>20</td>\n",
       "      <td>0.997597</td>\n",
       "      <td>0.997543</td>\n",
       "      <td>0.997056</td>\n",
       "      <td>0.997399</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.803109</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>1.348641</td>\n",
       "      <td>1.947975e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893309</td>\n",
       "      <td>0.895542</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.896071</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>21</td>\n",
       "      <td>0.998196</td>\n",
       "      <td>0.998119</td>\n",
       "      <td>0.998021</td>\n",
       "      <td>0.998112</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.851156</td>\n",
       "      <td>0.084926</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>1.948412e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.893074</td>\n",
       "      <td>0.894781</td>\n",
       "      <td>0.899977</td>\n",
       "      <td>0.895944</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>22</td>\n",
       "      <td>0.998202</td>\n",
       "      <td>0.998131</td>\n",
       "      <td>0.997989</td>\n",
       "      <td>0.998107</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50.738101</td>\n",
       "      <td>0.123003</td>\n",
       "      <td>3.931372</td>\n",
       "      <td>1.205526e-01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.893104</td>\n",
       "      <td>0.895290</td>\n",
       "      <td>0.899157</td>\n",
       "      <td>0.895850</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>23</td>\n",
       "      <td>0.997629</td>\n",
       "      <td>0.997558</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>0.997415</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.153401</td>\n",
       "      <td>0.076530</td>\n",
       "      <td>0.895623</td>\n",
       "      <td>2.654952e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.892863</td>\n",
       "      <td>0.895051</td>\n",
       "      <td>0.899367</td>\n",
       "      <td>0.895760</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>24</td>\n",
       "      <td>0.998171</td>\n",
       "      <td>0.998112</td>\n",
       "      <td>0.997972</td>\n",
       "      <td>0.998085</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.410942</td>\n",
       "      <td>0.070250</td>\n",
       "      <td>1.864145</td>\n",
       "      <td>6.420107e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.892974</td>\n",
       "      <td>0.895019</td>\n",
       "      <td>0.899202</td>\n",
       "      <td>0.895732</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>25</td>\n",
       "      <td>0.997575</td>\n",
       "      <td>0.997524</td>\n",
       "      <td>0.997071</td>\n",
       "      <td>0.997390</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>19.031997</td>\n",
       "      <td>0.154290</td>\n",
       "      <td>1.353852</td>\n",
       "      <td>2.945216e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893229</td>\n",
       "      <td>0.894637</td>\n",
       "      <td>0.899124</td>\n",
       "      <td>0.895663</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>26</td>\n",
       "      <td>0.997597</td>\n",
       "      <td>0.997474</td>\n",
       "      <td>0.997002</td>\n",
       "      <td>0.997358</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.904628</td>\n",
       "      <td>0.045989</td>\n",
       "      <td>0.468640</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.891625</td>\n",
       "      <td>0.895561</td>\n",
       "      <td>0.899741</td>\n",
       "      <td>0.895642</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>27</td>\n",
       "      <td>0.998156</td>\n",
       "      <td>0.998038</td>\n",
       "      <td>0.997889</td>\n",
       "      <td>0.998028</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30.268942</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>2.332789</td>\n",
       "      <td>4.479430e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.892893</td>\n",
       "      <td>0.895219</td>\n",
       "      <td>0.898733</td>\n",
       "      <td>0.895615</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>28</td>\n",
       "      <td>0.997585</td>\n",
       "      <td>0.997534</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997390</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36.293576</td>\n",
       "      <td>0.213556</td>\n",
       "      <td>2.889947</td>\n",
       "      <td>5.559527e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.892904</td>\n",
       "      <td>0.895231</td>\n",
       "      <td>0.898646</td>\n",
       "      <td>0.895593</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>29</td>\n",
       "      <td>0.997596</td>\n",
       "      <td>0.997543</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.997408</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42.281752</td>\n",
       "      <td>0.171281</td>\n",
       "      <td>3.337759</td>\n",
       "      <td>5.751568e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.892477</td>\n",
       "      <td>0.894739</td>\n",
       "      <td>0.898650</td>\n",
       "      <td>0.895289</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>30</td>\n",
       "      <td>0.997601</td>\n",
       "      <td>0.997556</td>\n",
       "      <td>0.997081</td>\n",
       "      <td>0.997413</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18.141578</td>\n",
       "      <td>0.140496</td>\n",
       "      <td>1.395509</td>\n",
       "      <td>3.681915e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.892783</td>\n",
       "      <td>0.894321</td>\n",
       "      <td>0.898325</td>\n",
       "      <td>0.895143</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>31</td>\n",
       "      <td>0.997528</td>\n",
       "      <td>0.997482</td>\n",
       "      <td>0.997027</td>\n",
       "      <td>0.997346</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13.059437</td>\n",
       "      <td>0.137964</td>\n",
       "      <td>0.895630</td>\n",
       "      <td>2.655191e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.892998</td>\n",
       "      <td>0.894167</td>\n",
       "      <td>0.898108</td>\n",
       "      <td>0.895091</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>32</td>\n",
       "      <td>0.997546</td>\n",
       "      <td>0.997496</td>\n",
       "      <td>0.997010</td>\n",
       "      <td>0.997351</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.488063</td>\n",
       "      <td>0.029457</td>\n",
       "      <td>0.484263</td>\n",
       "      <td>2.550987e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.891946</td>\n",
       "      <td>0.894198</td>\n",
       "      <td>0.898272</td>\n",
       "      <td>0.894805</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>33</td>\n",
       "      <td>0.998140</td>\n",
       "      <td>0.998032</td>\n",
       "      <td>0.997887</td>\n",
       "      <td>0.998019</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.925461</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>0.484261</td>\n",
       "      <td>1.275494e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.892365</td>\n",
       "      <td>0.893623</td>\n",
       "      <td>0.897551</td>\n",
       "      <td>0.894513</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>34</td>\n",
       "      <td>0.997469</td>\n",
       "      <td>0.997356</td>\n",
       "      <td>0.996898</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.236714</td>\n",
       "      <td>0.051551</td>\n",
       "      <td>0.895629</td>\n",
       "      <td>1.948041e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.891245</td>\n",
       "      <td>0.894420</td>\n",
       "      <td>0.897858</td>\n",
       "      <td>0.894508</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>35</td>\n",
       "      <td>0.997576</td>\n",
       "      <td>0.997432</td>\n",
       "      <td>0.997008</td>\n",
       "      <td>0.997338</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.498475</td>\n",
       "      <td>0.055596</td>\n",
       "      <td>0.484264</td>\n",
       "      <td>1.275786e-02</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.890718</td>\n",
       "      <td>0.893715</td>\n",
       "      <td>0.896495</td>\n",
       "      <td>0.893643</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>36</td>\n",
       "      <td>0.997464</td>\n",
       "      <td>0.997467</td>\n",
       "      <td>0.996909</td>\n",
       "      <td>0.997280</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.671718</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.057281</td>\n",
       "      <td>7.365640e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.871747</td>\n",
       "      <td>0.873728</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.874928</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>37</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>0.995925</td>\n",
       "      <td>0.995822</td>\n",
       "      <td>0.995952</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619647</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>0.057283</td>\n",
       "      <td>7.366094e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.870700</td>\n",
       "      <td>0.871773</td>\n",
       "      <td>0.878703</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>38</td>\n",
       "      <td>0.995778</td>\n",
       "      <td>0.995794</td>\n",
       "      <td>0.995660</td>\n",
       "      <td>0.995744</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.692544</td>\n",
       "      <td>0.019482</td>\n",
       "      <td>0.052075</td>\n",
       "      <td>7.361762e-03</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.871016</td>\n",
       "      <td>0.871899</td>\n",
       "      <td>0.877012</td>\n",
       "      <td>0.873309</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>39</td>\n",
       "      <td>0.995225</td>\n",
       "      <td>0.994727</td>\n",
       "      <td>0.994399</td>\n",
       "      <td>0.994784</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.630063</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>6.180516e-06</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.870824</td>\n",
       "      <td>0.871945</td>\n",
       "      <td>0.874433</td>\n",
       "      <td>0.872401</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>40</td>\n",
       "      <td>0.995121</td>\n",
       "      <td>0.994796</td>\n",
       "      <td>0.994884</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "17      46.176672      0.743398         3.342973    2.551143e-02   \n",
       "16      38.157726      1.052273         3.103431    3.437397e-01   \n",
       "19      56.528426      0.174090         4.426032    4.101676e-02   \n",
       "18      50.878694      0.121674         3.780363    3.374661e-02   \n",
       "15      31.305159      0.091977         2.317168    1.947881e-02   \n",
       "7       42.073466      0.162007         3.369003    5.154582e-02   \n",
       "14      25.197209      0.045978         1.843321    1.275893e-02   \n",
       "6       36.454998      0.250044         2.889946    3.375194e-02   \n",
       "8       48.561528      0.269463         3.874090    2.209057e-02   \n",
       "9       54.768409      0.413499         4.353146    9.573045e-02   \n",
       "37      44.067790      0.071017         3.322138    6.419739e-02   \n",
       "39      49.342595      4.641310         3.145095    3.326839e-01   \n",
       "13      18.792457      0.046005         1.379887    7.360526e-03   \n",
       "4       23.827745      0.157425         1.884976    2.655175e-02   \n",
       "38      50.566250      0.409157         3.837642    6.027848e-02   \n",
       "34      25.285750      0.099085         1.890169    2.551027e-02   \n",
       "5       30.529297      0.153234         2.374445    1.275396e-02   \n",
       "36      37.855707      0.197733         2.822254    3.682084e-02   \n",
       "35      31.976866      0.079664         2.337994    1.948317e-02   \n",
       "29      55.049591      0.630426         4.405221    1.470921e-01   \n",
       "3       17.803109      0.007358         1.348641    1.947975e-02   \n",
       "12      12.851156      0.084926         0.895628    1.948412e-02   \n",
       "28      50.738101      0.123003         3.931372    1.205526e-01   \n",
       "2       12.153401      0.076530         0.895623    2.654952e-02   \n",
       "24      24.410942      0.070250         1.864145    6.420107e-02   \n",
       "33      19.031997      0.154290         1.353852    2.945216e-02   \n",
       "11       6.904628      0.045989         0.468640    1.123916e-07   \n",
       "25      30.268942      0.106967         2.332789    4.479430e-02   \n",
       "26      36.293576      0.213556         2.889947    5.559527e-02   \n",
       "27      42.281752      0.171281         3.337759    5.751568e-02   \n",
       "23      18.141578      0.140496         1.395509    3.681915e-02   \n",
       "32      13.059437      0.137964         0.895630    2.655191e-02   \n",
       "1        6.488063      0.029457         0.484263    2.550987e-02   \n",
       "31       6.925461      0.073638         0.484261    1.275494e-02   \n",
       "22      12.236714      0.051551         0.895629    1.948041e-02   \n",
       "21       6.498475      0.055596         0.484264    1.275786e-02   \n",
       "10       0.671718      0.000002         0.057281    7.365640e-03   \n",
       "0        0.619647      0.007361         0.057283    7.366094e-03   \n",
       "30       0.692544      0.019482         0.052075    7.361762e-03   \n",
       "20       0.630063      0.007367         0.046864    6.180516e-06   \n",
       "\n",
       "   param_class_weight param_criterion param_n_estimators  \\\n",
       "17               None         entropy                780   \n",
       "16               None         entropy                670   \n",
       "19               None         entropy               1000   \n",
       "18               None         entropy                890   \n",
       "15               None         entropy                560   \n",
       "7                None            gini                780   \n",
       "14               None         entropy                450   \n",
       "6                None            gini                670   \n",
       "8                None            gini                890   \n",
       "9                None            gini               1000   \n",
       "37           balanced         entropy                780   \n",
       "39           balanced         entropy               1000   \n",
       "13               None         entropy                340   \n",
       "4                None            gini                450   \n",
       "38           balanced         entropy                890   \n",
       "34           balanced         entropy                450   \n",
       "5                None            gini                560   \n",
       "36           balanced         entropy                670   \n",
       "35           balanced         entropy                560   \n",
       "29           balanced            gini               1000   \n",
       "3                None            gini                340   \n",
       "12               None         entropy                230   \n",
       "28           balanced            gini                890   \n",
       "2                None            gini                230   \n",
       "24           balanced            gini                450   \n",
       "33           balanced         entropy                340   \n",
       "11               None         entropy                120   \n",
       "25           balanced            gini                560   \n",
       "26           balanced            gini                670   \n",
       "27           balanced            gini                780   \n",
       "23           balanced            gini                340   \n",
       "32           balanced         entropy                230   \n",
       "1                None            gini                120   \n",
       "31           balanced         entropy                120   \n",
       "22           balanced            gini                230   \n",
       "21           balanced            gini                120   \n",
       "10               None         entropy                 10   \n",
       "0                None            gini                 10   \n",
       "30           balanced         entropy                 10   \n",
       "20           balanced            gini                 10   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "17  {'class_weight': None, 'criterion': 'entropy',...           0.894313   \n",
       "16  {'class_weight': None, 'criterion': 'entropy',...           0.894590   \n",
       "19  {'class_weight': None, 'criterion': 'entropy',...           0.894219   \n",
       "18  {'class_weight': None, 'criterion': 'entropy',...           0.894154   \n",
       "15  {'class_weight': None, 'criterion': 'entropy',...           0.894229   \n",
       "7   {'class_weight': None, 'criterion': 'gini', 'n...           0.893878   \n",
       "14  {'class_weight': None, 'criterion': 'entropy',...           0.893480   \n",
       "6   {'class_weight': None, 'criterion': 'gini', 'n...           0.893930   \n",
       "8   {'class_weight': None, 'criterion': 'gini', 'n...           0.893569   \n",
       "9   {'class_weight': None, 'criterion': 'gini', 'n...           0.893440   \n",
       "37  {'class_weight': 'balanced', 'criterion': 'ent...           0.894058   \n",
       "39  {'class_weight': 'balanced', 'criterion': 'ent...           0.893959   \n",
       "13  {'class_weight': None, 'criterion': 'entropy',...           0.893714   \n",
       "4   {'class_weight': None, 'criterion': 'gini', 'n...           0.893501   \n",
       "38  {'class_weight': 'balanced', 'criterion': 'ent...           0.894034   \n",
       "34  {'class_weight': 'balanced', 'criterion': 'ent...           0.893945   \n",
       "5   {'class_weight': None, 'criterion': 'gini', 'n...           0.893302   \n",
       "36  {'class_weight': 'balanced', 'criterion': 'ent...           0.893615   \n",
       "35  {'class_weight': 'balanced', 'criterion': 'ent...           0.893350   \n",
       "29  {'class_weight': 'balanced', 'criterion': 'gin...           0.893357   \n",
       "3   {'class_weight': None, 'criterion': 'gini', 'n...           0.893309   \n",
       "12  {'class_weight': None, 'criterion': 'entropy',...           0.893074   \n",
       "28  {'class_weight': 'balanced', 'criterion': 'gin...           0.893104   \n",
       "2   {'class_weight': None, 'criterion': 'gini', 'n...           0.892863   \n",
       "24  {'class_weight': 'balanced', 'criterion': 'gin...           0.892974   \n",
       "33  {'class_weight': 'balanced', 'criterion': 'ent...           0.893229   \n",
       "11  {'class_weight': None, 'criterion': 'entropy',...           0.891625   \n",
       "25  {'class_weight': 'balanced', 'criterion': 'gin...           0.892893   \n",
       "26  {'class_weight': 'balanced', 'criterion': 'gin...           0.892904   \n",
       "27  {'class_weight': 'balanced', 'criterion': 'gin...           0.892477   \n",
       "23  {'class_weight': 'balanced', 'criterion': 'gin...           0.892783   \n",
       "32  {'class_weight': 'balanced', 'criterion': 'ent...           0.892998   \n",
       "1   {'class_weight': None, 'criterion': 'gini', 'n...           0.891946   \n",
       "31  {'class_weight': 'balanced', 'criterion': 'ent...           0.892365   \n",
       "22  {'class_weight': 'balanced', 'criterion': 'gin...           0.891245   \n",
       "21  {'class_weight': 'balanced', 'criterion': 'gin...           0.890718   \n",
       "10  {'class_weight': None, 'criterion': 'entropy',...           0.871747   \n",
       "0   {'class_weight': None, 'criterion': 'gini', 'n...           0.870700   \n",
       "30  {'class_weight': 'balanced', 'criterion': 'ent...           0.871016   \n",
       "20  {'class_weight': 'balanced', 'criterion': 'gin...           0.870824   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "17           0.896849           0.900955         0.897372        0.002737   \n",
       "16           0.896329           0.900542         0.897154        0.002499   \n",
       "19           0.896328           0.900782         0.897109        0.002736   \n",
       "18           0.896449           0.900382         0.896995        0.002572   \n",
       "15           0.896100           0.900372         0.896900        0.002571   \n",
       "7            0.896152           0.900261         0.896764        0.002641   \n",
       "14           0.896597           0.900106         0.896728        0.002707   \n",
       "6            0.895824           0.900354         0.896703        0.002695   \n",
       "8            0.896251           0.900232         0.896684        0.002737   \n",
       "9            0.896140           0.900286         0.896622        0.002815   \n",
       "37           0.895783           0.899849         0.896563        0.002428   \n",
       "39           0.895902           0.899687         0.896516        0.002378   \n",
       "13           0.896183           0.899635         0.896510        0.002428   \n",
       "4            0.895707           0.900139         0.896449        0.002760   \n",
       "38           0.896016           0.899165         0.896405        0.002113   \n",
       "34           0.896013           0.899087         0.896348        0.002112   \n",
       "5            0.895537           0.899831         0.896223        0.002709   \n",
       "36           0.895562           0.899296         0.896158        0.002357   \n",
       "35           0.896074           0.898938         0.896120        0.002282   \n",
       "29           0.895588           0.899280         0.896075        0.002442   \n",
       "3            0.895542           0.899362         0.896071        0.002499   \n",
       "12           0.894781           0.899977         0.895944        0.002936   \n",
       "28           0.895290           0.899157         0.895850        0.002503   \n",
       "2            0.895051           0.899367         0.895760        0.002702   \n",
       "24           0.895019           0.899202         0.895732        0.002592   \n",
       "33           0.894637           0.899124         0.895663        0.002513   \n",
       "11           0.895561           0.899741         0.895642        0.003314   \n",
       "25           0.895219           0.898733         0.895615        0.002401   \n",
       "26           0.895231           0.898646         0.895593        0.002358   \n",
       "27           0.894739           0.898650         0.895289        0.002550   \n",
       "23           0.894321           0.898325         0.895143        0.002336   \n",
       "32           0.894167           0.898108         0.895091        0.002186   \n",
       "1            0.894198           0.898272         0.894805        0.002618   \n",
       "31           0.893623           0.897551         0.894513        0.002209   \n",
       "22           0.894420           0.897858         0.894508        0.002701   \n",
       "21           0.893715           0.896495         0.893643        0.002359   \n",
       "10           0.873728           0.879310         0.874928        0.003202   \n",
       "0            0.871773           0.878703         0.873725        0.003547   \n",
       "30           0.871899           0.877012         0.873309        0.002643   \n",
       "20           0.871945           0.874433         0.872401        0.001508   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "17                1            0.998242            0.998151   \n",
       "16                2            0.998217            0.998133   \n",
       "19                3            0.998207            0.998142   \n",
       "18                4            0.998219            0.998145   \n",
       "15                5            0.998212            0.998136   \n",
       "7                 6            0.998223            0.998153   \n",
       "14                7            0.998230            0.998146   \n",
       "6                 8            0.998234            0.998134   \n",
       "8                 9            0.998225            0.998151   \n",
       "9                10            0.998219            0.998152   \n",
       "37               11            0.997588            0.997571   \n",
       "39               12            0.997608            0.997570   \n",
       "13               13            0.998188            0.998109   \n",
       "4                14            0.998246            0.998128   \n",
       "38               15            0.997621            0.997558   \n",
       "34               16            0.997609            0.997542   \n",
       "5                17            0.998240            0.998145   \n",
       "36               18            0.997590            0.997536   \n",
       "35               19            0.997592            0.997583   \n",
       "29               20            0.997597            0.997543   \n",
       "3                21            0.998196            0.998119   \n",
       "12               22            0.998202            0.998131   \n",
       "28               23            0.997629            0.997558   \n",
       "2                24            0.998171            0.998112   \n",
       "24               25            0.997575            0.997524   \n",
       "33               26            0.997597            0.997474   \n",
       "11               27            0.998156            0.998038   \n",
       "25               28            0.997585            0.997534   \n",
       "26               29            0.997596            0.997543   \n",
       "27               30            0.997601            0.997556   \n",
       "23               31            0.997528            0.997482   \n",
       "32               32            0.997546            0.997496   \n",
       "1                33            0.998140            0.998032   \n",
       "31               34            0.997469            0.997356   \n",
       "22               35            0.997576            0.997432   \n",
       "21               36            0.997464            0.997467   \n",
       "10               37            0.996109            0.995925   \n",
       "0                38            0.995778            0.995794   \n",
       "30               39            0.995225            0.994727   \n",
       "20               40            0.995121            0.994796   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "17            0.998040          0.998144         0.000083  \n",
       "16            0.998036          0.998128         0.000074  \n",
       "19            0.998037          0.998129         0.000070  \n",
       "18            0.998053          0.998139         0.000068  \n",
       "15            0.998026          0.998125         0.000076  \n",
       "7             0.998034          0.998136         0.000078  \n",
       "14            0.998023          0.998133         0.000085  \n",
       "6             0.998039          0.998136         0.000079  \n",
       "8             0.998028          0.998134         0.000081  \n",
       "9             0.998041          0.998138         0.000073  \n",
       "37            0.997063          0.997407         0.000244  \n",
       "39            0.997090          0.997423         0.000236  \n",
       "13            0.998008          0.998102         0.000074  \n",
       "4             0.998020          0.998132         0.000092  \n",
       "38            0.997075          0.997418         0.000244  \n",
       "34            0.997014          0.997389         0.000266  \n",
       "5             0.998042          0.998142         0.000081  \n",
       "36            0.997072          0.997399         0.000232  \n",
       "35            0.997028          0.997401         0.000264  \n",
       "29            0.997056          0.997399         0.000243  \n",
       "3             0.998021          0.998112         0.000072  \n",
       "12            0.997989          0.998107         0.000088  \n",
       "28            0.997059          0.997415         0.000254  \n",
       "2             0.997972          0.998085         0.000083  \n",
       "24            0.997071          0.997390         0.000226  \n",
       "33            0.997002          0.997358         0.000257  \n",
       "11            0.997889          0.998028         0.000109  \n",
       "25            0.997051          0.997390         0.000240  \n",
       "26            0.997083          0.997408         0.000231  \n",
       "27            0.997081          0.997413         0.000235  \n",
       "23            0.997027          0.997346         0.000226  \n",
       "32            0.997010          0.997351         0.000242  \n",
       "1             0.997887          0.998019         0.000103  \n",
       "31            0.996898          0.997241         0.000247  \n",
       "22            0.997008          0.997338         0.000241  \n",
       "21            0.996909          0.997280         0.000262  \n",
       "10            0.995822          0.995952         0.000118  \n",
       "0             0.995660          0.995744         0.000060  \n",
       "30            0.994399          0.994784         0.000340  \n",
       "20            0.994884          0.994934         0.000137  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` al estar ajustado se convierte en un estimador, por lo cual podemos usar el método predict, por debajo simplemente se usará el mejor estimador `grid.best_estimator_`. \n",
    "\n",
    "Para añadir el funcionamiento del mejor estimador obtenido por el modelo con nuestra funcion `evaluar_modelo` no usamos el objeto grid en si, ya que la funcion `cross_validate` hace multiples ajustes y evaluaciones (volveriamos a esperar los 8 minutos que a tardado un ajuste multiplicado por el número de validaciones cruzadas!).\n",
    "\n",
    "Para evaluar el funcionamiento del mejor estimador simplemente usamos la funcion con el mejor estimador directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_gridsearch\"] = evaluar_modelo(grid.best_estimator_, censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ahora vamos a realizar la misma optimización de parámetros pero usando `RandomizedSearchCV`. RandomizedSearchCV funciona de forma similar a GridSearchCV, pero en vez de evaluar todas las combinaciones posibles de hiperparámetros, se toman n muestras de hiperparámetros de dichas distribuciones.\n",
    "\n",
    "Se recomienda usar distribuciones en vez de valores fijos para hiperparámetros continuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a evaluar el funcionamiento de la busqueda aleatoria con los mísmos hiperparámetros que hemos usado en la busqueda en malla. Para `RandomizedSearchCV` tenemos que indicarle cuantas variantes de hiperparámetros utilizar (definidas por el parámetro n_iter, por defecto toma 10 variantes). Dado que dicha búsqueda toma muestreos el parámetro ya no se llama `param_grid` sino `param_distributions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda_random = RandomizedSearchCV(estimator = estimador_rf, \n",
    "                    param_distributions = parametros_busqueda_rf,\n",
    "                   scoring = \"roc_auc\", n_jobs = -1, n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min 56s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "busqueda_random.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda con 10 iteraciones ha tardado 1min 25s en mi máquina. Veamos como ha funcionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896911363494159\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=340, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(busqueda_random.best_score_)\n",
    "print(busqueda_random.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda de malla obtuvo un ROC AUC máximo de 0.89726431782 versus 0.896926092788 obtenido por la búsqueda aleatoria. Sin embargo la busqueda aleatoria ha tardado 8 veces menos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"rf_randomizedsearch\"] = evaluar_modelo(grid.best_estimator_, censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una ventaja del Randomized Search es que nos permite evaluar un espacio de hiperparámetros más amplio para un tiempo de computación similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver esto vamos a ampliar el espacio de búsqueda de hiperparámetros y hacer 100 muestreos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "param_dist_random = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": sp_randint(1, 11),\n",
    "    \"min_samples_split\": sp_randint(2, 11),\n",
    "    \"min_samples_leaf\": sp_randint(1, 11),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": np.linspace(10,1000,10).astype(int),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda_random_100 = RandomizedSearchCV(estimator=estimador_rf, \n",
    "                    param_distributions=param_dist_random,\n",
    "                   scoring=\"roc_auc\", n_jobs=-1, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 30s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "busqueda_random_100.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi máquina esta búsqueda ha tardado 8 minutos 54 segundos, un poco más que el grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918683396387896\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=8, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=9,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=230, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(busqueda_random_100.best_score_)\n",
    "print(busqueda_random_100.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La búsqueda aleatoria con los nuevos parámetros ha tardado un tiempo similar a la busqueda en malla, pero ha obtenido una puntuación máxima ROC AUC de 0.91950285418 (versus 0.89726431782 de la busqueda en malla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"rf_randomizedsearch_100\"] = evaluar_modelo(busqueda_random_100.best_estimator_,\n",
    "                                                      censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el estimador obtenido con la búsqueda aleatoria es el que mejor funciona.\n",
    "\n",
    "En general, salvo que el espacio de hiperparámetros que queramos explorar sea pequeño, es mejor el utilizar `RandomizedSearchCV` en vez de `GridSearchCV`. Esto es así por que en general no existe un unico conjunto de hiperparámetros que obtiene el mejor funcionamiento, sino que suelen existir multiples \"areas\" en el espacio dimensional de los hiperparámetros que funcionan de forma similar. Al hacer una búsqueda aleatoria podemos explorar las diversas areas en un tiempo más reducido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de parámetros dentro de un Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de busqueda de sklearn siguen la API de transformadores y estimadores. Esto significa que podemos crear un pipeline e incluir la optimización de hiperparámetros dentro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda_random_10 = RandomizedSearchCV(estimator=estimador_rf, \n",
    "                    param_distributions=param_dist_random,\n",
    "                   scoring=\"roc_auc\", n_jobs=-1, n_iter=10)\n",
    "\n",
    "pipeline_estimador = Pipeline(\n",
    "    [\n",
    "     (\"procesado\", pipeline_procesado),\n",
    "     (\"estimador\", busqueda_random_10)   \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos ajustar directamente en los datos originales sin tener que preprocesarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('procesado', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('transformacion_numericas', Pipeline(memory=None,\n",
       "     steps=[('selector_numerico', <__main__.ColumnExtractor object at 0x000002C3BC5BD1D0>), ('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbo... random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=0))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimador.fit(censo_X, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimador.predict(censo_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varias librerias externas que permiten hacer optimización de parámetros de forma más flexible y/o compleja que las implementaciones que soporta scikit-learn por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Scikit-optimize [(link)](https://scikit-optimize.github.io/)\n",
    "\n",
    "Scikit-Optimize, o skopt, es una librería que implementa multiples metodos para optimizar hiperparámetros de forma secuencial.\n",
    "\n",
    "Se instala con:\n",
    "\n",
    "`{sys.executable} -m pip install scikit-optimize` (existe una version en conda-forge pero solo de una version antigua)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La api de scikit-optimize no es tan similar a la de sklearn como seria posible, no obstante es muy facil de usar. Permite usar diversos algoritmos para ayudar al proceso de optimización, por ejemplo procesos gausianos o Bosques aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.2'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skopt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vez de usar un diccionario con el espacio de hiperparámetros que queremos buscar, scikit-optimize necesita pasarle una lista de parámetros.\n",
    "\n",
    "skopt es una libreria relativamente nueva, y tiene ciertas limitaciones comparada con scikitlearn. Por ejemplo, en vez de diccionarios con los nombres de los parámetros,  espera como inputs listas, no se pueden usar funciones de distribuciones (como scipy.randint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import space\n",
    "\n",
    "param_espacio_skopt = [\n",
    "    space.Integer(3, 10), #max_depth\n",
    "    space.Integer(1, 11), #max_features\n",
    "    (0.001, 0.99, \"uniform\"), #min_samples_split\n",
    "    (0.001, 0.5, \"uniform\"), #min_samples_leaf\n",
    "    space.Integer(1, 1000), #n_estimators\n",
    "    space.Categorical([\"gini\", \"entropy\"]), #criterion,\n",
    "    space.Categorical([True, False]), #bootstrap\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-optimize necesita que definamos la funcion objetivo, que ira variando en funcion de los parámetros elegidos. Dicha función tiene que crear el estimador y evaluarlo y devolver la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "estimador_rf = RandomForestClassifier()\n",
    "\n",
    "def funcion_optimizable(params):\n",
    "    #params es simplemente una selección especifica de hiperparámetros\n",
    "    max_depth, max_features, min_samples_split, min_samples_leaf,  n_estimators, criterion, bootstrap = params\n",
    "\n",
    "    estimador_rf.set_params(\n",
    "                   max_depth=max_depth,\n",
    "                   max_features=max_features,\n",
    "                   min_samples_split=min_samples_split, \n",
    "                   min_samples_leaf=min_samples_leaf,\n",
    "                   n_estimators=n_estimators,\n",
    "                   criterion=criterion\n",
    "                  )\n",
    "\n",
    "    return -np.mean(cross_val_score(estimador_rf, censo_X_procesado, censo_y, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos dejar que skopt optimize los outputs de la funcion `funcion_optimizable` mediante el uso de `gp_minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 21s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "resultado_gp = gp_minimize(funcion_optimizable, param_espacio_skopt, n_calls=10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "este proceso ha tardado 25 minutos en mi maquina con n_call = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro `x` nos da el vector con los parámetros con mejor funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resultado_gp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-440387a82f85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresultado_gp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'resultado_gp' is not defined"
     ]
    }
   ],
   "source": [
    "resultado_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resultado_gp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-7b3b1727157b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m estimador_skopt_gp_100 = RandomForestClassifier(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresultado_gp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresultado_gp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresultado_gp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresultado_gp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resultado_gp' is not defined"
     ]
    }
   ],
   "source": [
    "estimador_skopt_gp_100 = RandomForestClassifier(\n",
    "    max_depth=resultado_gp.x[0],\n",
    "    max_features=resultado_gp.x[1],\n",
    "    min_samples_split=resultado_gp.x[2], \n",
    "    min_samples_leaf=resultado_gp.x[3],\n",
    "    n_estimators=resultado_gp.x[4],\n",
    "    criterion=resultado_gp.x[5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimador_skopt_gp_100' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-e2978107d67d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresultados\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rf_skopt_gp_100\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluar_modelo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimador_skopt_gp_100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenso_X_procesado\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenso_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'estimador_skopt_gp_100' is not defined"
     ]
    }
   ],
   "source": [
    "resultados[\"rf_skopt_gp_100\"] = evaluar_modelo(estimador_skopt_gp_100, censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skopt (version >0.4) tambien tiene una implementacion de `BayesSearchCV`, que es un reemplazo de GridSearchCV pero que usa optimización bayesiana (en vez de probar todas las posibilidades)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV \n",
    "\n",
    "param_espacio_skopt_bayesCV = {\n",
    "     \"max_depth\": space.Integer(3, 10), #\n",
    "    \"max_features\": space.Integer(1, 11), #\n",
    "    \"min_samples_split\": space.Real(0.001, 0.99, \"uniform\"), #\n",
    "    \"min_samples_leaf\": space.Real(0.001, 0.5, \"uniform\"), #\n",
    "    \"n_estimators\": space.Integer(1, 1000), #\n",
    "    \"criterion\": space.Categorical([\"gini\", \"entropy\"]),\n",
    "    \"boostrap\": space.Categorical([True, False])\n",
    "}\n",
    "\n",
    "busqueda_bayesiano_skopt_100 = BayesSearchCV(\n",
    "    estimator=estimador_rf, \n",
    "    search_spaces=param_espacio_skopt_bayesCV,\n",
    "    scoring=\"roc_auc\", n_jobs=-1, n_iter=100,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter boostrap for estimator RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=10, max_features=7, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=0.14884047934633715,\n            min_samples_split=0.2739631910202954,\n            min_weight_fraction_leaf=0.0, n_estimators=166, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 514, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py\", line 215, in set_params\n    (key, self))\nValueError: Invalid parameter boostrap for estimator RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=10, max_features=7, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=0.14884047934633715,\n            min_samples_split=0.2739631910202954,\n            min_weight_fraction_leaf=0.0, n_estimators=166, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-b82e4ca421bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-n 1 -r 1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'busqueda_bayesiano_skopt_100.fit(censo_X_procesado, censo_y)\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2345\u001b[0m                 \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2346\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2347\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2348\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\decorator.py:decorator-gen-61>\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1149\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mall_runs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m         \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mworst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[0;32m    652\u001b[0m                 optim_result = self._step(\n\u001b[0;32m    653\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m                     \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m                 )\n\u001b[0;32m    656\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[0;32m    401\u001b[0m                 \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             )\n\u001b[1;32m--> 403\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m             for train, test in cv_iter)\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter boostrap for estimator RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=10, max_features=7, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=0.14884047934633715,\n            min_samples_split=0.2739631910202954,\n            min_weight_fraction_leaf=0.0, n_estimators=166, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "busqueda_bayesiano_skopt_100.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-e604b0180019>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbusqueda_bayesiano_skopt_100\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BayesSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "busqueda_bayesiano_skopt_100.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_bayesiano_skopt_100\"] = evaluar_modelo(busqueda_bayesiano_skopt_100.best_estimator_,\n",
    "                                                      censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>fit_time_idx</th>\n",
       "      <th>score_time_idx</th>\n",
       "      <th>test_score_idx</th>\n",
       "      <th>train_score_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.066678</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.783341</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>0.786865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.460645</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>0.906715</td>\n",
       "      <td>0.908326</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.986234</td>\n",
       "      <td>0.912413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.395003</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>0.995521</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.013264</td>\n",
       "      <td>0.950989</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_bayesiano_skopt_100</th>\n",
       "      <td>7.136472</td>\n",
       "      <td>0.193855</td>\n",
       "      <td>0.910383</td>\n",
       "      <td>0.914396</td>\n",
       "      <td>0.111627</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>0.990223</td>\n",
       "      <td>0.918510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_gridsearch</th>\n",
       "      <td>3.986320</td>\n",
       "      <td>0.236890</td>\n",
       "      <td>0.848783</td>\n",
       "      <td>0.849026</td>\n",
       "      <td>0.062353</td>\n",
       "      <td>0.177107</td>\n",
       "      <td>0.923221</td>\n",
       "      <td>0.852846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch</th>\n",
       "      <td>4.077757</td>\n",
       "      <td>0.253586</td>\n",
       "      <td>0.854896</td>\n",
       "      <td>0.855122</td>\n",
       "      <td>0.063783</td>\n",
       "      <td>0.189589</td>\n",
       "      <td>0.929870</td>\n",
       "      <td>0.858970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch_100</th>\n",
       "      <td>63.931399</td>\n",
       "      <td>1.337555</td>\n",
       "      <td>0.919371</td>\n",
       "      <td>0.958161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_skopt_gp_100</th>\n",
       "      <td>1.557633</td>\n",
       "      <td>0.057794</td>\n",
       "      <td>0.906729</td>\n",
       "      <td>0.910607</td>\n",
       "      <td>0.024364</td>\n",
       "      <td>0.043208</td>\n",
       "      <td>0.986249</td>\n",
       "      <td>0.914704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fit_time  score_time  test_score  train_score  \\\n",
       "naive_bayes               0.066678    0.014363    0.781202     0.783341   \n",
       "reg_logistica             0.460645    0.018298    0.906715     0.908326   \n",
       "rf                        0.395003    0.017742    0.874312     0.995521   \n",
       "rf_bayesiano_skopt_100    7.136472    0.193855    0.910383     0.914396   \n",
       "rf_gridsearch             3.986320    0.236890    0.848783     0.849026   \n",
       "rf_randomizedsearch       4.077757    0.253586    0.854896     0.855122   \n",
       "rf_randomizedsearch_100  63.931399    1.337555    0.919371     0.958161   \n",
       "rf_skopt_gp_100           1.557633    0.057794    0.906729     0.910607   \n",
       "\n",
       "                         fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "naive_bayes                  0.001043        0.010738        0.849714   \n",
       "reg_logistica                0.007205        0.013680        0.986234   \n",
       "rf                           0.006179        0.013264        0.950989   \n",
       "rf_bayesiano_skopt_100       0.111627        0.144932        0.990223   \n",
       "rf_gridsearch                0.062353        0.177107        0.923221   \n",
       "rf_randomizedsearch          0.063783        0.189589        0.929870   \n",
       "rf_randomizedsearch_100      1.000000        1.000000        1.000000   \n",
       "rf_skopt_gp_100              0.024364        0.043208        0.986249   \n",
       "\n",
       "                         train_score_idx  \n",
       "naive_bayes                     0.786865  \n",
       "reg_logistica                   0.912413  \n",
       "rf                              1.000000  \n",
       "rf_bayesiano_skopt_100          0.918510  \n",
       "rf_gridsearch                   0.852846  \n",
       "rf_randomizedsearch             0.858970  \n",
       "rf_randomizedsearch_100         0.962472  \n",
       "rf_skopt_gp_100                 0.914704  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_resultados()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperopt-sklearn [(link)](https://github.com/hyperopt/hyperopt-sklearn)\n",
    "\n",
    "Hyperopt-sklearn es una implementación de Hyperopt, que es la librería más famosa para optimización de hiperparámetros) pero preparado para funcionar con scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hpsklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/cb/61b99f73621e2692abd0e730f7888a9983d01f626868336fa1db1d57bc1e/hpsklearn-0.1.0.tar.gz\n",
      "Collecting hyperopt (from hpsklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/63/12/704382c3081df3ae3f9d96fe6afb62efa2fa9749be20c301cd2797fb0b52/hyperopt-0.1.2-py3-none-any.whl (115kB)\n",
      "Collecting nose (from hpsklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from hpsklearn) (1.16.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from hpsklearn) (0.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from hpsklearn) (1.2.1)\n",
      "Collecting pymongo (from hyperopt->hpsklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/10/35/f081e8f16cb357cc1e082743fed98fb699f3b9f215addc1b4b8bd1b58472/pymongo-3.7.2-cp37-cp37m-win_amd64.whl (311kB)\n",
      "Collecting tqdm (from hyperopt->hpsklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from hyperopt->hpsklearn) (2.2)\n",
      "Collecting future (from hyperopt->hpsklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/52/e20466b85000a181e1e144fd8305caf2cf475e2f9674e797b222f8105f5f/future-0.17.1.tar.gz (829kB)\n",
      "Requirement already satisfied: six in c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from hyperopt->hpsklearn) (1.12.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from networkx->hyperopt->hpsklearn) (4.4.0)\n",
      "Building wheels for collected packages: hpsklearn, future\n",
      "  Building wheel for hpsklearn (setup.py): started\n",
      "  Building wheel for hpsklearn (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\jorge\\AppData\\Local\\pip\\Cache\\wheels\\41\\ee\\c4\\3c267cbf78f0905434ee36b915d97a20610ad3af7ff3c75852\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\jorge\\AppData\\Local\\pip\\Cache\\wheels\\0c\\61\\d2\\d6b7317325828fbb39ee6ad559dbe4664d0896da4721bf379e\n",
      "Successfully built hpsklearn future\n",
      "Installing collected packages: pymongo, tqdm, future, hyperopt, nose, hpsklearn\n",
      "Successfully installed future-0.17.1 hpsklearn-0.1.0 hyperopt-0.1.2 nose-1.3.7 pymongo-3.7.2 tqdm-4.31.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install hpsklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from hpsklearn import HyperoptEstimator, random_forest\n",
    "\n",
    "optimizador_hpsklearn = HyperoptEstimator( classifier=random_forest('estimador_rf'),\n",
    "                                       seed=42, loss_fn=roc_auc_score, max_evals=10, trial_timeout=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 1/1 [00:40<00:00, 40.15s/it, best loss: 0.7802446951964176]\n",
      "100%|█████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.94s/it, best loss: 0.7802446951964176]\n",
      "100%|█████████████████████████████████████████████████████| 1/1 [00:42<00:00, 42.59s/it, best loss: 0.7710649043354366]\n",
      "100%|█████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.08s/it, best loss: 0.6205629198046001]\n",
      "100%|█████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.44s/it, best loss: 0.6205629198046001]\n",
      "100%|█████████████████████████████████████████████████████| 1/1 [00:28<00:00, 28.92s/it, best loss: 0.6205629198046001]\n",
      "100%|█████████████████████████████████████████████████████| 1/1 [00:57<00:00, 57.09s/it, best loss: 0.6205629198046001]\n",
      "100%|█████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.12s/it, best loss: 0.6171504172603297]\n",
      "100%|█████████████████████████████████████████████████████| 1/1 [00:56<00:00, 56.94s/it, best loss: 0.6171504172603297]\n",
      "100%|█████████████████████████████████████████████████████| 1/1 [00:57<00:00, 57.03s/it, best loss: 0.6171504172603297]\n",
      "5min 7s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "optimizador_hpsklearn.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HyperoptEstimator` nos devuelve un estimador que podemos usar como cualquiera de los de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizador_hpsklearn.predict(censo_X_procesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con `best_model()` podemos ver el mejor modelo producido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=2, max_features=0.32993202225925455,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=75, n_jobs=1, oob_score=False, random_state=2,\n",
       "             verbose=False, warm_start=False),\n",
       " 'preprocs': (Normalizer(copy=True, norm='l1'),),\n",
       " 'ex_preprocs': ()}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#estimador_hpsklearn.best_model()\n",
    "optimizador_hpsklearn.best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el estimador de hyperopt-sklearn tambien puede añadir pasos de preprocesamiento automáticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo_hpsklearn = estimador_hpsklearn.best_model()[\"learner\"]\n",
    "modelo_hpsklearn = optimizador_hpsklearn.best_model()[\"learner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"rf_hpsklearn_10\"] = evaluar_modelo(modelo_hpsklearn, censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>fit_time_idx</th>\n",
       "      <th>score_time_idx</th>\n",
       "      <th>test_score_idx</th>\n",
       "      <th>train_score_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.843554</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.906715</td>\n",
       "      <td>0.908326</td>\n",
       "      <td>0.010787</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.987005</td>\n",
       "      <td>0.910349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.218701</td>\n",
       "      <td>0.043737</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.783341</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.850378</td>\n",
       "      <td>0.785085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.731085</td>\n",
       "      <td>0.028119</td>\n",
       "      <td>0.874262</td>\n",
       "      <td>0.995482</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.951679</td>\n",
       "      <td>0.997699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>78.197806</td>\n",
       "      <td>11.003671</td>\n",
       "      <td>0.908628</td>\n",
       "      <td>0.910540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989088</td>\n",
       "      <td>0.912568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_gridsearch</th>\n",
       "      <td>50.231964</td>\n",
       "      <td>1.715222</td>\n",
       "      <td>0.896489</td>\n",
       "      <td>0.997770</td>\n",
       "      <td>0.642371</td>\n",
       "      <td>0.155877</td>\n",
       "      <td>0.975873</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch</th>\n",
       "      <td>51.531673</td>\n",
       "      <td>1.940171</td>\n",
       "      <td>0.896380</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>0.658991</td>\n",
       "      <td>0.176320</td>\n",
       "      <td>0.975755</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch_100</th>\n",
       "      <td>18.714364</td>\n",
       "      <td>0.396787</td>\n",
       "      <td>0.918653</td>\n",
       "      <td>0.962459</td>\n",
       "      <td>0.239321</td>\n",
       "      <td>0.036059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_hpsklearn_10</th>\n",
       "      <td>2.758735</td>\n",
       "      <td>0.078110</td>\n",
       "      <td>0.885977</td>\n",
       "      <td>0.886425</td>\n",
       "      <td>0.035279</td>\n",
       "      <td>0.007099</td>\n",
       "      <td>0.964430</td>\n",
       "      <td>0.888399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fit_time  score_time  test_score  train_score  \\\n",
       "reg_logistica             0.843554    0.018744    0.906715     0.908326   \n",
       "naive_bayes               0.218701    0.043737    0.781202     0.783341   \n",
       "rf                        0.731085    0.028119    0.874262     0.995482   \n",
       "svc                      78.197806   11.003671    0.908628     0.910540   \n",
       "rf_gridsearch            50.231964    1.715222    0.896489     0.997770   \n",
       "rf_randomizedsearch      51.531673    1.940171    0.896380     0.997778   \n",
       "rf_randomizedsearch_100  18.714364    0.396787    0.918653     0.962459   \n",
       "rf_hpsklearn_10           2.758735    0.078110    0.885977     0.886425   \n",
       "\n",
       "                         fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "reg_logistica                0.010787        0.001703        0.987005   \n",
       "naive_bayes                  0.002797        0.003975        0.850378   \n",
       "rf                           0.009349        0.002555        0.951679   \n",
       "svc                          1.000000        1.000000        0.989088   \n",
       "rf_gridsearch                0.642371        0.155877        0.975873   \n",
       "rf_randomizedsearch          0.658991        0.176320        0.975755   \n",
       "rf_randomizedsearch_100      0.239321        0.036059        1.000000   \n",
       "rf_hpsklearn_10              0.035279        0.007099        0.964430   \n",
       "\n",
       "                         train_score_idx  \n",
       "reg_logistica                   0.910349  \n",
       "naive_bayes                     0.785085  \n",
       "rf                              0.997699  \n",
       "svc                             0.912568  \n",
       "rf_gridsearch                   0.999992  \n",
       "rf_randomizedsearch             1.000000  \n",
       "rf_randomizedsearch_100         0.964602  \n",
       "rf_hpsklearn_10                 0.888399  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_resultados()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modo de prueba, he dejado el Optimizador de hyperopt-sklearn toda la noche corriendo. Lo bueno de este estimador es que en cualquier momento podemos parar el proceso (dandole en el notebook a `kernel->interrup` y el optimizador seguira conservando el modelo mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import any_classifier, any_preprocessing\n",
    "\n",
    "estimador_final = HyperoptEstimator( classifier=any_classifier(\"clf\"), \n",
    "                                    preprocessing=any_preprocessing(\"preproc\"),\n",
    "                                    seed=42, loss_fn=roc_auc_score, max_evals=20) #max_evals=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimador_final.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex_preprocs': (),\n",
       " 'learner': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.016925014519856875, loss='deviance',\n",
       "               max_depth=2, max_features=0.3243309842493083,\n",
       "               max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "               min_impurity_split=None, min_samples_leaf=1,\n",
       "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "               n_estimators=46, presort='auto', random_state=4,\n",
       "               subsample=1.0, verbose=0, warm_start=False),\n",
       " 'preprocs': (PCA(copy=True, iterated_power='auto', n_components=88, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False),)}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimador_final.best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelo_hpsklearn_final = Pipeline([\n",
    "    (\"preprocs\", estimador_final.best_model()[\"preprocs\"][0]),\n",
    "    (\"learner\", estimador_final.best_model()[\"learner\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_hpsklearn_final\"] = evaluar_modelo(modelo_hpsklearn_final, censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>fit_time_idx</th>\n",
       "      <th>score_time_idx</th>\n",
       "      <th>test_score_idx</th>\n",
       "      <th>train_score_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.066678</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.783341</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>0.786865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.460645</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>0.906715</td>\n",
       "      <td>0.908326</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.986234</td>\n",
       "      <td>0.912413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.395003</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>0.995521</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.013264</td>\n",
       "      <td>0.950989</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_bayesiano_skopt_100</th>\n",
       "      <td>7.136472</td>\n",
       "      <td>0.193855</td>\n",
       "      <td>0.910383</td>\n",
       "      <td>0.914396</td>\n",
       "      <td>0.111627</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>0.990223</td>\n",
       "      <td>0.918510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_gridsearch</th>\n",
       "      <td>3.986320</td>\n",
       "      <td>0.236890</td>\n",
       "      <td>0.848783</td>\n",
       "      <td>0.849026</td>\n",
       "      <td>0.062353</td>\n",
       "      <td>0.177107</td>\n",
       "      <td>0.923221</td>\n",
       "      <td>0.852846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_hpsklearn_10</th>\n",
       "      <td>11.909622</td>\n",
       "      <td>0.755976</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.890850</td>\n",
       "      <td>0.186288</td>\n",
       "      <td>0.565193</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.894859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_hpsklearn_final</th>\n",
       "      <td>4.160803</td>\n",
       "      <td>0.031582</td>\n",
       "      <td>0.877192</td>\n",
       "      <td>0.880618</td>\n",
       "      <td>0.065082</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>0.954122</td>\n",
       "      <td>0.884580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch</th>\n",
       "      <td>4.077757</td>\n",
       "      <td>0.253586</td>\n",
       "      <td>0.854896</td>\n",
       "      <td>0.855122</td>\n",
       "      <td>0.063783</td>\n",
       "      <td>0.189589</td>\n",
       "      <td>0.929870</td>\n",
       "      <td>0.858970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch_100</th>\n",
       "      <td>63.931399</td>\n",
       "      <td>1.337555</td>\n",
       "      <td>0.919371</td>\n",
       "      <td>0.958161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_skopt_gp_100</th>\n",
       "      <td>1.329353</td>\n",
       "      <td>0.042163</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.909874</td>\n",
       "      <td>0.020793</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>0.984731</td>\n",
       "      <td>0.913968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fit_time  score_time  test_score  train_score  \\\n",
       "naive_bayes               0.066678    0.014363    0.781202     0.783341   \n",
       "reg_logistica             0.460645    0.018298    0.906715     0.908326   \n",
       "rf                        0.395003    0.017742    0.874312     0.995521   \n",
       "rf_bayesiano_skopt_100    7.136472    0.193855    0.910383     0.914396   \n",
       "rf_gridsearch             3.986320    0.236890    0.848783     0.849026   \n",
       "rf_hpsklearn_10          11.909622    0.755976    0.889492     0.890850   \n",
       "rf_hpsklearn_final        4.160803    0.031582    0.877192     0.880618   \n",
       "rf_randomizedsearch       4.077757    0.253586    0.854896     0.855122   \n",
       "rf_randomizedsearch_100  63.931399    1.337555    0.919371     0.958161   \n",
       "rf_skopt_gp_100           1.329353    0.042163    0.905333     0.909874   \n",
       "\n",
       "                         fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "naive_bayes                  0.001043        0.010738        0.849714   \n",
       "reg_logistica                0.007205        0.013680        0.986234   \n",
       "rf                           0.006179        0.013264        0.950989   \n",
       "rf_bayesiano_skopt_100       0.111627        0.144932        0.990223   \n",
       "rf_gridsearch                0.062353        0.177107        0.923221   \n",
       "rf_hpsklearn_10              0.186288        0.565193        0.967500   \n",
       "rf_hpsklearn_final           0.065082        0.023612        0.954122   \n",
       "rf_randomizedsearch          0.063783        0.189589        0.929870   \n",
       "rf_randomizedsearch_100      1.000000        1.000000        1.000000   \n",
       "rf_skopt_gp_100              0.020793        0.031522        0.984731   \n",
       "\n",
       "                         train_score_idx  \n",
       "naive_bayes                     0.786865  \n",
       "reg_logistica                   0.912413  \n",
       "rf                              1.000000  \n",
       "rf_bayesiano_skopt_100          0.918510  \n",
       "rf_gridsearch                   0.852846  \n",
       "rf_hpsklearn_10                 0.894859  \n",
       "rf_hpsklearn_final              0.884580  \n",
       "rf_randomizedsearch             0.858970  \n",
       "rf_randomizedsearch_100         0.962472  \n",
       "rf_skopt_gp_100                 0.913968  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_resultados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
