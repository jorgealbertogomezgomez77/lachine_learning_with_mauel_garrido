{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-06T00:54:09-06:00\n",
      "\n",
      "CPython 3.7.3rc1\n",
      "IPython 7.3.0\n",
      "\n",
      "compiler   : MSC v.1916 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "      <th>col_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>-50</td>\n",
       "      <td>0.771666</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>-5</td>\n",
       "      <td>1.068558</td>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>-32</td>\n",
       "      <td>0.846396</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>-84</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "      <td>Una olla de algo más vaca que carnero, salpicó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>65</td>\n",
       "      <td>4.540614</td>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2      col3  col_outliers  col_outliers2  \\\n",
       "0              59.0  52.0  2.232832           -50       0.771666   \n",
       "1              31.0  74.0  0.906147            -5       1.068558   \n",
       "2              81.0  28.0  0.626750           -32       0.846396   \n",
       "3              34.0  16.0  0.816738           -84       0.637381   \n",
       "4              32.0  28.0  0.571131            65       4.540614   \n",
       "\n",
       "  col_categorica col_ordinal  \\\n",
       "0          ratón    muy bien   \n",
       "1       elefante     regular   \n",
       "2          ratón     muy mal   \n",
       "3           gato         mal   \n",
       "4           gato        bien   \n",
       "\n",
       "                                           col_texto  \n",
       "0  Tenía en su casa una ama que pasaba de los cua...  \n",
       "1  El resto della concluían sayo de velarte, calz...  \n",
       "2  El resto della concluían sayo de velarte, calz...  \n",
       "3  Una olla de algo más vaca que carnero, salpicó...  \n",
       "4  Tenía en su casa una ama que pasaba de los cua...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv(\"D:/datasets/Curso_Mauel_Garrido/datos_procesamiento.csv\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1    float64\n",
       "col2                float64\n",
       "col3                float64\n",
       "col_outliers          int64\n",
       "col_outliers2       float64\n",
       "col_categorica       object\n",
       "col_ordinal          object\n",
       "col_texto            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputación de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1    float64\n",
       "col2                float64\n",
       "col3                float64\n",
       "col_outliers          int64\n",
       "col_outliers2       float64\n",
       "col_categorica       object\n",
       "col_ordinal          object\n",
       "col_texto            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col_inexistente1', 'col2', 'col3', 'col_outliers2'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df = datos.select_dtypes([int, float])\n",
    "var_numericas_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df[var_numericas_df.isnull().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.270999</td>\n",
       "      <td>1.067230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.394209</td>\n",
       "      <td>4.145716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.437365</td>\n",
       "      <td>20.549474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.324893</td>\n",
       "      <td>0.761684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3.664671</td>\n",
       "      <td>3.154153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    col_inexistente1  col2      col3  col_outliers2\n",
       "9                NaN  53.0  2.270999       1.067230\n",
       "10               NaN  99.0  1.394209       4.145716\n",
       "16               NaN  50.0  0.437365      20.549474\n",
       "17               NaN  73.0  0.324893       0.761684\n",
       "23               NaN  85.0  3.664671       3.154153"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df[var_numericas_df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "imputador = preprocessing.Imputer(strategy = \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_numericas_imputadas = imputador.fit_transform(var_numericas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59.        , 52.        ,  2.23283208,  0.77166646],\n",
       "       [31.        , 74.        ,  0.90614714,  1.06855838],\n",
       "       [81.        , 28.        ,  0.62675042,  0.84639576],\n",
       "       ...,\n",
       "       [19.        , 53.        ,  0.73723413,  1.34525201],\n",
       "       [88.        , 94.        ,  0.76008706,  1.3692463 ],\n",
       "       [94.        , 56.        ,  1.2299403 ,  0.94395714]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>0.771666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>1.068558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>0.846396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>0.637381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>4.540614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.618844</td>\n",
       "      <td>0.812940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.167880</td>\n",
       "      <td>1.235137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.229813</td>\n",
       "      <td>1.283176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.407978</td>\n",
       "      <td>1.298613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.382743</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.270999</td>\n",
       "      <td>1.067230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2       col3  col_outliers2\n",
       "0         59.000000  52.0   2.232832       0.771666\n",
       "1         31.000000  74.0   0.906147       1.068558\n",
       "2         81.000000  28.0   0.626750       0.846396\n",
       "3         34.000000  16.0   0.816738       0.637381\n",
       "4         32.000000  28.0   0.571131       4.540614\n",
       "5         81.000000   4.0   1.618844       0.812940\n",
       "6         57.000000  31.0   0.167880       1.235137\n",
       "7         34.000000  20.0  20.229813       1.283176\n",
       "8         37.000000  96.0   2.407978       1.298613\n",
       "9         48.382743  53.0   2.270999       1.067230"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_df = pd.DataFrame(var_numericas_imputadas,\n",
    "                                                   index=var_numericas_df.index,\n",
    "                                                   columns=var_numericas_df.columns)\n",
    "\n",
    "var_numericas_imputadas_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_df[var_numericas_imputadas_df.isnull().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estandarización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de Estandardización es un proceso requerido por una gran cantidad de modelos en Scikit-learn. El objetivo es obtener una variable con media 0 y desviación estándar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col_inexistente1', 'col2', 'col3', 'col_outliers2'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1     48.382743\n",
       "col2                 49.660000\n",
       "col3                  1.466095\n",
       "col_outliers2       131.193340\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1      27.987174\n",
       "col2                  28.272668\n",
       "col3                   1.732358\n",
       "col_outliers2       3401.164776\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello el transformador mas sencillo en sklearn es [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador = preprocessing.StandardScaler()\n",
    "var_numericas_imputadas_escalado_standard = escalador.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 48.38274336,  49.66      ,   1.46609489, 131.19333968])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escalador.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.86197757e-17,  1.26121336e-16, -3.81916720e-17, -3.55271368e-18])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_standard.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_standard.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39921733,  0.08280686,  0.44281884, -0.03836537])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_standard[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aquellos casos en los que los datos tengan muchos valores extremos, es posible que estandarizar usando la media y la desviacion estandar no funcione bien en el modelo. Para esos casos es mejor usar unos estimadores mas robustos (menos sensibles a outliers) y emplear un [RobustScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler) que funciona substrayendo la mediana y escalando mediante el rango intercuartil (IQR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_robusto = preprocessing.RobustScaler()\n",
    "var_numericas_imputadas_escalado_robusto = escalador_robusto.fit_transform(\n",
    "                                                        var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.81916720e-17, -2.85106383e-02,  4.01958704e-01,  7.03130782e+01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_robusto.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.33218559e-01, 6.01245275e-01, 1.38651621e+00, 1.83690817e+03])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_robusto.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escalado a un rango especifico**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay casos en los que en vez de estandardizar queremos escalar los datos a un rango (generalmente [-1,1] o [0,1]). Para ello podemos usar [MinMaxScaler](scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler) que hace escalado minmax (obviamente) o [MaxAbscaler](scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbscaler) que simplemente divide cada valor de una variable por su valor máximo (y por tanto convierte el valor maximo a 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.72774653276077"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107357.85777352"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_minmax = preprocessing.MinMaxScaler()\n",
    "var_numericas_imputadas_escalado_minmax = escalador_minmax.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_minmax.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_minmax.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_maxabs = preprocessing.MaxAbsScaler()\n",
    "var_numericas_imputadas_escalado_maxabs = escalador_maxabs.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_maxabs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00019307153628649718"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_maxabs.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hay casos en los que lo que se necesita es tener observaciones con norma unitaria (norma L2 o euclidiana). Para esos casos, podemos usar [Normalizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = preprocessing.Normalizer()\n",
    "var_numericas_imputadas_normal = normalizador.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que el objetivo del Normalizer es normalizar casos, no variables (o sea que funciona por filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38632582, 0.92219711, 0.01129252, 0.01331651])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_normal[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(var_numericas_imputadas_normal[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Otras transformaciones**\n",
    "\n",
    "Para aquellos casos en los que queremos aplicar una función arbitraria a una variable podemos usar [FunctionTransformer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, la variable `col3` no tiene una distribución normal, sino que tiene una asimetria muy marcada (es una distribución lognormal). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(datos.col3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una práctica frecuente es aplicar el logaritmo a dichas variables para convertirlas a variables con una distribución mas normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "col3_transformada = transformer.transform(datos[[\"col3\"]])\n",
    "col3_transformada = col3_transformada.reshape(col3_transformada.shape[0],)\n",
    "sns.kdeplot(col3_transformada);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Variables Categoricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos están diseñados para trabajar con variables numéricas. Esto implica que para poder entrenar los modelos con variables categóricas tenemos que convertirlas a números. Este proceso se llama *codificación (encoding)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "      <th>col_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>-50</td>\n",
       "      <td>0.771666</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>-5</td>\n",
       "      <td>1.068558</td>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>-32</td>\n",
       "      <td>0.846396</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>-84</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "      <td>Una olla de algo más vaca que carnero, salpicó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>65</td>\n",
       "      <td>4.540614</td>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2      col3  col_outliers  col_outliers2  \\\n",
       "0              59.0  52.0  2.232832           -50       0.771666   \n",
       "1              31.0  74.0  0.906147            -5       1.068558   \n",
       "2              81.0  28.0  0.626750           -32       0.846396   \n",
       "3              34.0  16.0  0.816738           -84       0.637381   \n",
       "4              32.0  28.0  0.571131            65       4.540614   \n",
       "\n",
       "  col_categorica col_ordinal  \\\n",
       "0          ratón    muy bien   \n",
       "1       elefante     regular   \n",
       "2          ratón     muy mal   \n",
       "3           gato         mal   \n",
       "4           gato        bien   \n",
       "\n",
       "                                           col_texto  \n",
       "0  Tenía en su casa una ama que pasaba de los cua...  \n",
       "1  El resto della concluían sayo de velarte, calz...  \n",
       "2  El resto della concluían sayo de velarte, calz...  \n",
       "3  Una olla de algo más vaca que carnero, salpicó...  \n",
       "4  Tenía en su casa una ama que pasaba de los cua...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv(\"D:/datasets/Curso_Mauel_Garrido/datos_procesamiento.csv\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_categoricas = datos[['col_categorica', 'col_ordinal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col_categorica col_ordinal\n",
       "0          ratón    muy bien\n",
       "1       elefante     regular\n",
       "2          ratón     muy mal\n",
       "3           gato         mal\n",
       "4           gato        bien"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_categoricas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchas formas de codificar variables, la más sencilla es reemplazar los elementos de dichas variables por un número. Por ejemplo, si hacemos esto con la columna `col_categorica`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador = preprocessing.LabelEncoder()\n",
    "label_codificador.fit(datos.col_ordinal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bien', 'mal', 'muy bien', 'muy mal', 'regular'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.transform(['muy bien', 'muy mal', 'muy bien', 'muy mal', 'bien'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bien', 'bien', 'mal', 'muy bien'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.inverse_transform([0, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de variables ordinales esto tiene sentido ya que `muy_bien>bien>regular>mal>muy mal`. Sin embargo, esto indica a los modelos de scikit-learn por ejemplo que `mal + regular = bien`. Esto se puede usar en según que casos (hay modelos que no interpretan las variables numéricas así), o para codificar las variables objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para variables categóricas (por ejemplo animales) no tiene sentido usar este tipo de encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 1, 1, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador_categorico = preprocessing.LabelEncoder()\n",
    "label_codificador_categorico.fit_transform(datos.col_categorica)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['elefante', 'gato', 'perro', 'ratón'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador_categorico.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digamos que no tiene sentido decir que la media de `elefante` y `perro` no es `gato`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para estos casos una técnica que se puede usar se llama `one-hot encoding`. Lo que significa es que creamos n columnas binarias, con el valor 0 por defecto salvo la columna referente a la observación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esto podemos usar \n",
    "[OneHotEncoder](scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_codificador = preprocessing.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['ratón' 'elefante' 'ratón' 'gato' 'gato' 'perro' 'perro' 'perro'\n 'elefante' 'elefante' 'perro' 'elefante' 'gato' 'ratón' 'gato' 'ratón'\n 'elefante' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'ratón' 'gato'\n 'gato' 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'gato' 'elefante' 'gato' 'gato' 'gato'\n 'gato' 'ratón' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'gato'\n 'elefante' 'perro' 'ratón' 'perro' 'elefante' 'ratón' 'ratón' 'gato'\n 'gato' 'elefante' 'ratón' 'perro' 'gato' 'gato' 'gato' 'gato' 'ratón'\n 'elefante' 'elefante' 'perro' 'gato' 'ratón' 'perro' 'elefante' 'gato'\n 'gato' 'ratón' 'ratón' 'elefante' 'perro' 'ratón' 'ratón' 'elefante'\n 'gato' 'perro' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'perro'\n 'perro' 'ratón' 'gato' 'ratón' 'gato' 'gato' 'elefante' 'gato' 'gato'\n 'perro' 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'perro' 'gato'\n 'gato' 'ratón' 'gato' 'perro' 'perro' 'perro' 'gato' 'perro' 'perro'\n 'elefante' 'perro' 'ratón' 'gato' 'gato' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'elefante' 'elefante' 'perro' 'ratón' 'gato' 'elefante'\n 'gato' 'ratón' 'ratón' 'elefante' 'gato' 'perro' 'ratón' 'gato'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'perro' 'perro' 'gato' 'perro' 'perro' 'elefante' 'gato'\n 'perro' 'perro' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'ratón' 'elefante' 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'ratón' 'perro' 'perro' 'gato' 'ratón' 'gato' 'perro' 'ratón'\n 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'ratón' 'elefante'\n 'gato' 'gato' 'perro' 'elefante' 'perro' 'perro' 'gato' 'elefante'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'gato' 'gato' 'elefante' 'ratón' 'perro'\n 'perro' 'ratón' 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'perro'\n 'gato' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'perro' 'elefante'\n 'gato' 'gato' 'ratón' 'ratón' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón' 'ratón' 'perro'\n 'elefante' 'perro' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'perro' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'perro' 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'ratón' 'gato' 'ratón' 'gato' 'perro'\n 'gato' 'perro' 'ratón' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón' 'gato'\n 'ratón' 'gato' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'gato' 'elefante' 'ratón' 'elefante' 'perro' 'elefante' 'elefante'\n 'perro' 'gato' 'gato' 'elefante' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'perro' 'ratón' 'ratón' 'gato' 'elefante' 'gato' 'gato' 'perro' 'ratón'\n 'perro' 'perro' 'elefante' 'ratón' 'ratón' 'gato' 'perro' 'perro'\n 'elefante' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'perro' 'ratón' 'gato' 'perro' 'perro' 'gato'\n 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'elefante' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'perro' 'gato' 'gato'\n 'ratón' 'ratón' 'ratón' 'perro' 'elefante' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'elefante' 'ratón' 'elefante' 'perro' 'ratón'\n 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'gato' 'ratón' 'elefante'\n 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'ratón' 'ratón' 'perro' 'perro' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'ratón' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'ratón' 'perro' 'perro' 'gato' 'perro' 'gato' 'gato' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'elefante' 'ratón' 'elefante' 'gato' 'ratón'\n 'gato' 'gato' 'ratón' 'perro' 'ratón' 'elefante' 'ratón' 'elefante'\n 'gato' 'gato' 'gato' 'gato' 'perro' 'gato' 'gato' 'ratón' 'perro'\n 'elefante' 'gato' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'elefante' 'ratón' 'perro' 'gato' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'elefante' 'elefante' 'perro' 'perro' 'ratón' 'perro' 'perro'\n 'ratón' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón'\n 'gato' 'perro' 'gato' 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón'\n 'ratón' 'elefante' 'gato' 'gato' 'elefante' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'elefante' 'elefante'\n 'elefante' 'perro' 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro' 'perro' 'perro'\n 'gato' 'ratón' 'elefante' 'perro' 'elefante' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'elefante' 'perro' 'ratón' 'elefante'\n 'elefante' 'perro' 'gato' 'ratón' 'ratón' 'elefante' 'elefante' 'gato'\n 'ratón' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'perro' 'perro'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'ratón' 'elefante'\n 'ratón' 'gato' 'perro' 'gato' 'elefante' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'gato' 'gato' 'elefante' 'perro' 'perro' 'gato' 'perro' 'gato'\n 'ratón' 'gato' 'ratón' 'perro' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'perro' 'gato' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'perro' 'gato' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'elefante'\n 'gato' 'perro' 'gato' 'gato' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'ratón' 'perro' 'elefante' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'perro' 'ratón' 'gato' 'gato' 'perro' 'perro'\n 'perro' 'gato' 'perro' 'elefante' 'elefante' 'perro' 'perro' 'elefante'\n 'ratón' 'gato' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'gato' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'perro' 'ratón' 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'perro' 'perro' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'ratón'\n 'perro' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'perro' 'gato' 'perro'\n 'perro' 'gato' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'elefante'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'elefante'\n 'ratón' 'perro' 'perro' 'perro' 'elefante' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'elefante' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'elefante'\n 'perro' 'perro' 'perro' 'elefante' 'perro' 'perro' 'elefante' 'perro'\n 'elefante' 'gato' 'elefante' 'gato' 'gato' 'perro' 'gato' 'ratón'\n 'elefante' 'perro' 'perro' 'perro' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'gato' 'ratón' 'gato' 'gato' 'ratón' 'elefante' 'gato'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro'\n 'ratón' 'gato' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'ratón' 'gato' 'gato'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'perro' 'perro' 'perro'\n 'perro' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'gato' 'gato' 'gato' 'perro' 'ratón' 'perro' 'ratón'\n 'elefante' 'perro' 'perro' 'ratón' 'elefante' 'ratón' 'elefante' 'ratón'\n 'gato' 'gato' 'gato' 'perro' 'elefante' 'gato' 'perro' 'gato' 'ratón'\n 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'gato' 'ratón'\n 'ratón' 'ratón' 'gato' 'elefante' 'perro' 'perro' 'elefante' 'ratón'\n 'perro' 'elefante' 'ratón' 'gato' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'perro' 'perro' 'elefante' 'gato' 'ratón' 'ratón'\n 'elefante' 'ratón' 'elefante' 'elefante' 'elefante'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-c3430f1a49b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moh_codificador\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol_categorica\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \"\"\"\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mX_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dtype'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    550\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['ratón' 'elefante' 'ratón' 'gato' 'gato' 'perro' 'perro' 'perro'\n 'elefante' 'elefante' 'perro' 'elefante' 'gato' 'ratón' 'gato' 'ratón'\n 'elefante' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'ratón' 'gato'\n 'gato' 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'gato' 'elefante' 'gato' 'gato' 'gato'\n 'gato' 'ratón' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'gato'\n 'elefante' 'perro' 'ratón' 'perro' 'elefante' 'ratón' 'ratón' 'gato'\n 'gato' 'elefante' 'ratón' 'perro' 'gato' 'gato' 'gato' 'gato' 'ratón'\n 'elefante' 'elefante' 'perro' 'gato' 'ratón' 'perro' 'elefante' 'gato'\n 'gato' 'ratón' 'ratón' 'elefante' 'perro' 'ratón' 'ratón' 'elefante'\n 'gato' 'perro' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'perro'\n 'perro' 'ratón' 'gato' 'ratón' 'gato' 'gato' 'elefante' 'gato' 'gato'\n 'perro' 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'perro' 'gato'\n 'gato' 'ratón' 'gato' 'perro' 'perro' 'perro' 'gato' 'perro' 'perro'\n 'elefante' 'perro' 'ratón' 'gato' 'gato' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'elefante' 'elefante' 'perro' 'ratón' 'gato' 'elefante'\n 'gato' 'ratón' 'ratón' 'elefante' 'gato' 'perro' 'ratón' 'gato'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'perro' 'perro' 'gato' 'perro' 'perro' 'elefante' 'gato'\n 'perro' 'perro' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'ratón' 'elefante' 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'ratón' 'perro' 'perro' 'gato' 'ratón' 'gato' 'perro' 'ratón'\n 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'ratón' 'elefante'\n 'gato' 'gato' 'perro' 'elefante' 'perro' 'perro' 'gato' 'elefante'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'gato' 'gato' 'elefante' 'ratón' 'perro'\n 'perro' 'ratón' 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'perro'\n 'gato' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'perro' 'elefante'\n 'gato' 'gato' 'ratón' 'ratón' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón' 'ratón' 'perro'\n 'elefante' 'perro' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'perro' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'perro' 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'ratón' 'gato' 'ratón' 'gato' 'perro'\n 'gato' 'perro' 'ratón' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón' 'gato'\n 'ratón' 'gato' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'gato' 'elefante' 'ratón' 'elefante' 'perro' 'elefante' 'elefante'\n 'perro' 'gato' 'gato' 'elefante' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'perro' 'ratón' 'ratón' 'gato' 'elefante' 'gato' 'gato' 'perro' 'ratón'\n 'perro' 'perro' 'elefante' 'ratón' 'ratón' 'gato' 'perro' 'perro'\n 'elefante' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'perro' 'ratón' 'gato' 'perro' 'perro' 'gato'\n 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'elefante' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'perro' 'gato' 'gato'\n 'ratón' 'ratón' 'ratón' 'perro' 'elefante' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'elefante' 'ratón' 'elefante' 'perro' 'ratón'\n 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'gato' 'ratón' 'elefante'\n 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'ratón' 'ratón' 'perro' 'perro' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'ratón' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'ratón' 'perro' 'perro' 'gato' 'perro' 'gato' 'gato' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'elefante' 'ratón' 'elefante' 'gato' 'ratón'\n 'gato' 'gato' 'ratón' 'perro' 'ratón' 'elefante' 'ratón' 'elefante'\n 'gato' 'gato' 'gato' 'gato' 'perro' 'gato' 'gato' 'ratón' 'perro'\n 'elefante' 'gato' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'elefante' 'ratón' 'perro' 'gato' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'elefante' 'elefante' 'perro' 'perro' 'ratón' 'perro' 'perro'\n 'ratón' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón'\n 'gato' 'perro' 'gato' 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón'\n 'ratón' 'elefante' 'gato' 'gato' 'elefante' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'elefante' 'elefante'\n 'elefante' 'perro' 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro' 'perro' 'perro'\n 'gato' 'ratón' 'elefante' 'perro' 'elefante' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'elefante' 'perro' 'ratón' 'elefante'\n 'elefante' 'perro' 'gato' 'ratón' 'ratón' 'elefante' 'elefante' 'gato'\n 'ratón' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'perro' 'perro'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'ratón' 'elefante'\n 'ratón' 'gato' 'perro' 'gato' 'elefante' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'gato' 'gato' 'elefante' 'perro' 'perro' 'gato' 'perro' 'gato'\n 'ratón' 'gato' 'ratón' 'perro' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'perro' 'gato' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'perro' 'gato' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'elefante'\n 'gato' 'perro' 'gato' 'gato' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'ratón' 'perro' 'elefante' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'perro' 'ratón' 'gato' 'gato' 'perro' 'perro'\n 'perro' 'gato' 'perro' 'elefante' 'elefante' 'perro' 'perro' 'elefante'\n 'ratón' 'gato' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'gato' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'perro' 'ratón' 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'perro' 'perro' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'ratón'\n 'perro' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'perro' 'gato' 'perro'\n 'perro' 'gato' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'elefante'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'elefante'\n 'ratón' 'perro' 'perro' 'perro' 'elefante' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'elefante' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'elefante'\n 'perro' 'perro' 'perro' 'elefante' 'perro' 'perro' 'elefante' 'perro'\n 'elefante' 'gato' 'elefante' 'gato' 'gato' 'perro' 'gato' 'ratón'\n 'elefante' 'perro' 'perro' 'perro' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'gato' 'ratón' 'gato' 'gato' 'ratón' 'elefante' 'gato'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro'\n 'ratón' 'gato' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'ratón' 'gato' 'gato'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'perro' 'perro' 'perro'\n 'perro' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'gato' 'gato' 'gato' 'perro' 'ratón' 'perro' 'ratón'\n 'elefante' 'perro' 'perro' 'ratón' 'elefante' 'ratón' 'elefante' 'ratón'\n 'gato' 'gato' 'gato' 'perro' 'elefante' 'gato' 'perro' 'gato' 'ratón'\n 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'gato' 'ratón'\n 'ratón' 'ratón' 'gato' 'elefante' 'perro' 'perro' 'elefante' 'ratón'\n 'perro' 'elefante' 'ratón' 'gato' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'perro' 'perro' 'elefante' 'gato' 'ratón' 'ratón'\n 'elefante' 'ratón' 'elefante' 'elefante' 'elefante'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "oh_codificador.fit(datos.col_categorica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que OneHotEncoder falla cuando se le pasan strings en vez de numeros. Por ello primero tenemos que convertir las variables categóricas a numéricas usando LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias_codificadas = label_codificador_categorico.transform(datos.col_categorica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 1, 1, 2, 2, 2, 0, 0, 2, 0, 1, 3, 1, 3, 0, 3, 3, 0, 3, 3,\n",
       "       3, 1, 1, 3, 1, 0, 1, 0, 0, 0, 0, 3, 0, 1, 0, 1, 1, 1, 1, 3, 0, 1,\n",
       "       1, 2, 0, 1, 0, 2, 3, 2, 0, 3, 3, 1, 1, 0, 3, 2, 1, 1, 1, 1, 3, 0,\n",
       "       0, 2, 1, 3, 2, 0, 1, 1, 3, 3, 0, 2, 3, 3, 0, 1, 2, 3, 1, 0, 0, 2,\n",
       "       2, 2, 3, 1, 3, 1, 1, 0, 1, 1, 2, 2, 3, 2, 1, 0, 3, 2, 1, 1, 3, 1,\n",
       "       2, 2, 2, 1, 2, 2, 0, 2, 3, 1, 1, 1, 1, 3, 3, 3, 2, 0, 0, 2, 3, 1,\n",
       "       0, 1, 3, 3, 0, 1, 2, 3, 1, 0, 0, 0, 0, 2, 0, 0, 1, 3, 2, 2, 1, 2,\n",
       "       2, 0, 1, 2, 2, 2, 2, 1, 3, 1, 1, 1, 2, 3, 3, 0, 3, 3, 0, 0, 3, 0,\n",
       "       0, 0, 3, 3, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 3, 2, 2, 1, 3, 1, 2, 3,\n",
       "       0, 3, 3, 1, 3, 1, 3, 0, 1, 1, 2, 0, 2, 2, 1, 0, 0, 0, 1, 2, 1, 2,\n",
       "       0, 0, 0, 0, 2, 1, 1, 0, 3, 2, 2, 3, 3, 2, 2, 0, 0, 2, 1, 2, 3, 2,\n",
       "       3, 1, 3, 2, 0, 1, 1, 3, 3, 2, 1, 3, 3, 2, 0, 1, 3, 2, 0, 3, 0, 2,\n",
       "       3, 2, 2, 2, 3, 3, 3, 2, 0, 2, 0, 1, 0, 0, 0, 0, 3, 0, 3, 0, 2, 3,\n",
       "       1, 0, 2, 2, 3, 2, 3, 1, 1, 2, 1, 3, 2, 0, 1, 2, 1, 0, 2, 3, 1, 2,\n",
       "       0, 0, 1, 3, 1, 0, 2, 2, 3, 1, 3, 1, 2, 1, 2, 3, 3, 2, 3, 1, 1, 3,\n",
       "       3, 1, 2, 0, 0, 1, 3, 1, 3, 1, 3, 0, 3, 3, 0, 0, 1, 0, 3, 0, 2, 0,\n",
       "       0, 2, 1, 1, 0, 2, 2, 2, 2, 1, 2, 3, 3, 1, 0, 1, 1, 2, 3, 2, 2, 0,\n",
       "       3, 3, 1, 2, 2, 0, 1, 2, 1, 1, 3, 3, 1, 2, 1, 3, 2, 2, 3, 1, 2, 2,\n",
       "       1, 1, 2, 0, 3, 3, 2, 0, 0, 1, 3, 0, 2, 3, 0, 2, 2, 1, 0, 0, 0, 3,\n",
       "       2, 1, 1, 3, 3, 3, 2, 0, 1, 1, 1, 2, 0, 1, 0, 0, 0, 3, 1, 2, 0, 0,\n",
       "       0, 3, 0, 2, 3, 3, 3, 0, 3, 3, 1, 3, 2, 2, 3, 1, 0, 2, 1, 1, 3, 0,\n",
       "       3, 3, 3, 1, 3, 2, 0, 3, 3, 3, 2, 3, 3, 2, 2, 1, 2, 3, 2, 0, 3, 0,\n",
       "       1, 2, 1, 0, 3, 2, 2, 1, 2, 1, 1, 2, 1, 0, 0, 3, 3, 1, 1, 1, 2, 0,\n",
       "       1, 3, 0, 0, 3, 3, 2, 1, 1, 0, 0, 3, 0, 1, 3, 1, 1, 3, 2, 3, 0, 3,\n",
       "       0, 1, 1, 1, 1, 2, 1, 1, 3, 2, 0, 1, 1, 3, 2, 0, 3, 3, 0, 3, 2, 1,\n",
       "       2, 2, 2, 2, 1, 3, 1, 0, 2, 1, 2, 3, 3, 2, 0, 0, 0, 2, 2, 3, 2, 2,\n",
       "       3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 2, 1, 3, 2, 2, 2, 3, 3, 3, 0, 1, 1,\n",
       "       0, 1, 1, 3, 3, 3, 2, 2, 0, 0, 0, 0, 0, 2, 3, 3, 3, 1, 3, 1, 1, 0,\n",
       "       0, 0, 2, 3, 2, 2, 2, 1, 3, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 3, 0, 0,\n",
       "       2, 1, 3, 3, 0, 0, 1, 3, 3, 3, 0, 3, 3, 2, 2, 2, 0, 0, 0, 1, 3, 0,\n",
       "       3, 1, 2, 1, 0, 1, 3, 1, 1, 0, 1, 1, 0, 2, 2, 1, 2, 1, 3, 1, 3, 2,\n",
       "       2, 3, 0, 2, 2, 1, 2, 1, 2, 0, 3, 0, 2, 2, 1, 2, 2, 1, 3, 1, 1, 0,\n",
       "       1, 2, 1, 1, 2, 1, 3, 3, 2, 1, 1, 0, 3, 2, 0, 0, 3, 3, 2, 1, 2, 3,\n",
       "       1, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 0, 3, 1, 3, 1, 0, 0, 2, 3, 1, 0,\n",
       "       2, 2, 1, 1, 3, 2, 2, 3, 2, 3, 1, 2, 0, 3, 3, 2, 1, 2, 2, 2, 0, 2,\n",
       "       1, 3, 3, 2, 3, 1, 1, 3, 2, 3, 3, 2, 0, 1, 3, 0, 0, 2, 1, 2, 2, 1,\n",
       "       3, 2, 3, 1, 3, 0, 0, 2, 0, 2, 1, 3, 1, 2, 0, 0, 3, 0, 3, 0, 0, 3,\n",
       "       2, 2, 2, 0, 3, 1, 1, 1, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 3, 1, 1, 3,\n",
       "       2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 2, 1, 3, 0, 2, 2, 2,\n",
       "       0, 2, 3, 1, 0, 1, 3, 1, 1, 3, 0, 1, 0, 0, 1, 2, 1, 0, 2, 3, 0, 0,\n",
       "       0, 0, 2, 3, 2, 3, 1, 0, 3, 3, 2, 0, 3, 3, 2, 1, 0, 3, 3, 1, 1, 0,\n",
       "       2, 0, 2, 1, 2, 2, 2, 2, 3, 3, 1, 2, 1, 0, 2, 3, 2, 3, 2, 1, 0, 3,\n",
       "       1, 2, 3, 2, 0, 1, 3, 2, 0, 3, 3, 3, 2, 1, 1, 1, 2, 3, 2, 3, 0, 2,\n",
       "       2, 3, 0, 3, 0, 3, 1, 1, 1, 2, 0, 1, 2, 1, 3, 3, 1, 0, 1, 0, 0, 1,\n",
       "       3, 3, 3, 1, 0, 2, 2, 0, 3, 2, 0, 3, 1, 2, 3, 1, 1, 3, 3, 1, 2, 2,\n",
       "       2, 0, 1, 3, 3, 0, 3, 0, 0, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_codificadas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_oh_codificadas = oh_codificador.fit_transform(categorias_codificadas.reshape(1000,1))\n",
    "categorias_oh_codificadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que por defecto `OneHotEncoder` no devuelve un numpy array, sino una matriz `sparse`. La traducción sería \"matriz escasa\", y es una manera de representar matrices con muchos ceros (como es el caso de OneHot encoding) para consumir poca memoria.\n",
    "\n",
    "Podemos convertir dichas matrices a arrays facilmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_oh_codificadas.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos ahora la comparación en memoria de una matriz sparse versus su correspondiente np.array usando la función `sys.getsizeof` que devuelve el uso de memoria un objeto de python en bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(categorias_oh_codificadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32112"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(categorias_oh_codificadas.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos que el encoder devuelva arrays no tenemos más que pasarle el parametro `sparse=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_codificador = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "categorias_oh_codificadas = oh_codificador.fit_transform(categorias_codificadas.reshape(1000,1))\n",
    "categorias_oh_codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function feature_indices_ is deprecated; The ``feature_indices_`` attribute was deprecated in version 0.20 and will be removed 0.22.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_codificador.feature_indices_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas tiene la funcion auxiliar `get_dummies` que hace esto automáticamente de forma más fácil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elefante</th>\n",
       "      <th>gato</th>\n",
       "      <th>perro</th>\n",
       "      <th>ratón</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elefante  gato  perro  ratón\n",
       "0         0     0      0      1\n",
       "1         1     0      0      0\n",
       "2         0     0      0      1\n",
       "3         0     1      0      0\n",
       "4         0     1      0      0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(datos.col_categorica).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera.',\n",
       "       'El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino.',\n",
       "       'El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino.',\n",
       "       'Una olla de algo más vaca que carnero, salpicón las más noches, duelos y quebrantos los sábados, lentejas los viernes, algún palomino de añadidura los domingos, consumían las tres partes de su hacienda.',\n",
       "       'Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera.',\n",
       "       'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor.',\n",
       "       'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor.',\n",
       "       'El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino.',\n",
       "       'Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera.',\n",
       "       'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.col_texto.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para convertir texto en variables numéricas, podemos proceder de igual forma que con las variables categóricas, simplemente separando las palabras antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello tenemos dos vectorizadores en scikit-learn, que convierten texto en vectores.\n",
    "\n",
    "\n",
    "[CountVectorizer]() devuelve un vector con el valor 0 en todas las palabras que no existen en una frase y con el numero de ocurrencias de las palabras que si existen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un ejemplo para que se vea bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo_frases = ['los coches rojos',\n",
    "          'los aviones son rojos',\n",
    "          'los coches y los aviones son rojos',\n",
    "          'los camiones rojos'\n",
    "                 ]\n",
    "\n",
    "\n",
    "vectorizador_count = feature_extraction.text.CountVectorizer()\n",
    "X = vectorizador_count.fit_transform(ejemplo_frases)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aviones', 'camiones', 'coches', 'los', 'rojos', 'son']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aviones</th>\n",
       "      <th>camiones</th>\n",
       "      <th>coches</th>\n",
       "      <th>los</th>\n",
       "      <th>rojos</th>\n",
       "      <th>son</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aviones  camiones  coches  los  rojos  son\n",
       "0        0         0       1    1      1    0\n",
       "1        1         0       0    1      1    1\n",
       "2        1         0       1    2      1    1\n",
       "3        0         1       0    1      1    0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray(), columns=vectorizador_count.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tomar simplemente el número de veces que aparece cada palabra tiene un problema, y es que da un mayor peso a aquellas palabras que aparecen muchas veces pero que no aportan ningun valor semántico (por ejemplo, `los`). Una manera más sofisticada de vectorizar un texto es en vez de usar el número de apariciones, usar TF-IDF. TF-IDF se traduce como Frecuencia de Texto - Frecuencia Inversa de Documento, y es una medida que asigna pesos a cada palabra en función de su frecuencia de aparición en todos los documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aviones</th>\n",
       "      <th>camiones</th>\n",
       "      <th>coches</th>\n",
       "      <th>los</th>\n",
       "      <th>rojos</th>\n",
       "      <th>son</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730064</td>\n",
       "      <td>0.483222</td>\n",
       "      <td>0.483222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.589645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.390280</td>\n",
       "      <td>0.390280</td>\n",
       "      <td>0.589645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.438931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438931</td>\n",
       "      <td>0.581047</td>\n",
       "      <td>0.290524</td>\n",
       "      <td>0.438931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419880</td>\n",
       "      <td>0.419880</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aviones  camiones    coches       los     rojos       son\n",
       "0  0.000000  0.000000  0.730064  0.483222  0.483222  0.000000\n",
       "1  0.589645  0.000000  0.000000  0.390280  0.390280  0.589645\n",
       "2  0.438931  0.000000  0.438931  0.581047  0.290524  0.438931\n",
       "3  0.000000  0.804612  0.000000  0.419880  0.419880  0.000000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_tfidf = feature_extraction.text.TfidfVectorizer()\n",
    "X = vectorizador_tfidf.fit_transform(ejemplo_frases)\n",
    "pd.DataFrame(X.toarray(), columns=vectorizador_tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x134 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 28295 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_tfidf = feature_extraction.text.TfidfVectorizer()\n",
    "texto_vectorizado = vectorizador_tfidf.fit_transform(datos.col_texto)\n",
    "texto_vectorizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_vectorizado = texto_vectorizado.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bien', 'mal', 'muy bien', 'muy mal', 'regular'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Poniendolo todo junto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\jorge\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "col_numericas =  ['col_inexistente1', 'col2', 'col3', 'col_outliers', 'col_outliers2']\n",
    "col_categorica = ['col_categorica']\n",
    "col_texto = ['col_texto']\n",
    "\n",
    "\n",
    "#Variables numéricas\n",
    "imputador = preprocessing.Imputer(strategy=\"mean\")\n",
    "escalador = preprocessing.StandardScaler()\n",
    "var_numericas_imputadas_escalado_standard = escalador.fit_transform(\n",
    "                                                imputador.fit_transform(datos[col_numericas])\n",
    "                                            )\n",
    "df_numerico_procesado = pd.DataFrame(var_numericas_imputadas_escalado_standard,\n",
    "                                                   columns=col_numericas)\n",
    "\n",
    "\n",
    "# Variable categorica\n",
    "label_codificador_categorico = preprocessing.LabelEncoder()\n",
    "categorias_codificadas = label_codificador_categorico.fit_transform(datos[col_categorica])\n",
    "oh_codificador = preprocessing.OneHotEncoder(sparse=False)\n",
    "categorias_oh_codificadas = oh_codificador.fit_transform(categorias_codificadas.reshape(1000,1))\n",
    "\n",
    "df_categorico_procesado = pd.DataFrame(categorias_oh_codificadas, \n",
    "                                       columns=label_codificador_categorico.classes_)\n",
    "\n",
    "\n",
    "# Texto\n",
    "vectorizador_tfidf = feature_extraction.text.TfidfVectorizer()\n",
    "texto_vectorizado = vectorizador_tfidf.fit_transform(datos.col_texto)\n",
    "df_texto_procesado =  pd.DataFrame(texto_vectorizado.toarray(), columns=vectorizador_tfidf.get_feature_names())\n",
    "\n",
    "\n",
    "datos_procesados = pd.concat([\n",
    "    df_numerico_procesado,\n",
    "    df_categorico_procesado,\n",
    "    df_texto_procesado \n",
    "], axis=1)\n",
    "\n",
    "# variable ordinal\n",
    "label_codificador_ordinal = preprocessing.LabelEncoder()\n",
    "datos_procesados['col_ordinal'] = label_codificador_ordinal.fit_transform(datos.col_ordinal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>elefante</th>\n",
       "      <th>gato</th>\n",
       "      <th>perro</th>\n",
       "      <th>ratón</th>\n",
       "      <th>acordarme</th>\n",
       "      <th>...</th>\n",
       "      <th>vaca</th>\n",
       "      <th>veinte</th>\n",
       "      <th>velarte</th>\n",
       "      <th>vellori</th>\n",
       "      <th>velludo</th>\n",
       "      <th>verdad</th>\n",
       "      <th>verosímiles</th>\n",
       "      <th>viernes</th>\n",
       "      <th>vivía</th>\n",
       "      <th>col_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.399217</td>\n",
       "      <td>0.082807</td>\n",
       "      <td>0.442819</td>\n",
       "      <td>-0.694600</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.653605</td>\n",
       "      <td>0.861333</td>\n",
       "      <td>-0.323390</td>\n",
       "      <td>-0.118466</td>\n",
       "      <td>-0.038278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.226435</td>\n",
       "      <td>-0.766494</td>\n",
       "      <td>-0.484752</td>\n",
       "      <td>-0.464146</td>\n",
       "      <td>-0.038343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.540803</td>\n",
       "      <td>-1.191145</td>\n",
       "      <td>-0.375028</td>\n",
       "      <td>-1.129901</td>\n",
       "      <td>-0.038405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.616004</td>\n",
       "      <td>-0.766494</td>\n",
       "      <td>-0.516874</td>\n",
       "      <td>0.777743</td>\n",
       "      <td>-0.037257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.226435</td>\n",
       "      <td>-1.615795</td>\n",
       "      <td>0.088218</td>\n",
       "      <td>0.598501</td>\n",
       "      <td>-0.038353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.324016</td>\n",
       "      <td>-0.660332</td>\n",
       "      <td>-0.749767</td>\n",
       "      <td>0.944181</td>\n",
       "      <td>-0.038229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.540803</td>\n",
       "      <td>-1.049595</td>\n",
       "      <td>10.836735</td>\n",
       "      <td>1.136226</td>\n",
       "      <td>-0.038215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.428000</td>\n",
       "      <td>1.639859</td>\n",
       "      <td>0.543972</td>\n",
       "      <td>0.636910</td>\n",
       "      <td>-0.038210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118194</td>\n",
       "      <td>0.464862</td>\n",
       "      <td>0.739334</td>\n",
       "      <td>-0.038278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.746022</td>\n",
       "      <td>-0.041517</td>\n",
       "      <td>1.200241</td>\n",
       "      <td>-0.037373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.038431</td>\n",
       "      <td>-1.155757</td>\n",
       "      <td>-0.404065</td>\n",
       "      <td>-1.257931</td>\n",
       "      <td>-0.038157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.352799</td>\n",
       "      <td>-0.377231</td>\n",
       "      <td>-0.578128</td>\n",
       "      <td>-1.270734</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.578403</td>\n",
       "      <td>-0.978820</td>\n",
       "      <td>-0.369566</td>\n",
       "      <td>-1.257931</td>\n",
       "      <td>-0.038441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.076032</td>\n",
       "      <td>0.684395</td>\n",
       "      <td>-0.020709</td>\n",
       "      <td>-0.438540</td>\n",
       "      <td>-0.038455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.390399</td>\n",
       "      <td>1.533696</td>\n",
       "      <td>-0.621890</td>\n",
       "      <td>-0.195284</td>\n",
       "      <td>-0.038343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012032</td>\n",
       "      <td>-0.594129</td>\n",
       "      <td>0.700925</td>\n",
       "      <td>-0.032547</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825945</td>\n",
       "      <td>-0.659086</td>\n",
       "      <td>1.200241</td>\n",
       "      <td>-0.038368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.744028</td>\n",
       "      <td>-1.049595</td>\n",
       "      <td>-0.557416</td>\n",
       "      <td>-1.270734</td>\n",
       "      <td>-0.037935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.888028</td>\n",
       "      <td>-0.872657</td>\n",
       "      <td>-0.139629</td>\n",
       "      <td>0.176003</td>\n",
       "      <td>-0.038333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.352799</td>\n",
       "      <td>-1.191145</td>\n",
       "      <td>-0.657547</td>\n",
       "      <td>-0.758615</td>\n",
       "      <td>-0.038463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.136012</td>\n",
       "      <td>-1.615795</td>\n",
       "      <td>-0.314097</td>\n",
       "      <td>0.777743</td>\n",
       "      <td>-0.038579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.292819</td>\n",
       "      <td>1.427534</td>\n",
       "      <td>0.149977</td>\n",
       "      <td>-0.438540</td>\n",
       "      <td>-0.038486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250596</td>\n",
       "      <td>1.269758</td>\n",
       "      <td>-0.668994</td>\n",
       "      <td>-0.037665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.790447</td>\n",
       "      <td>0.436682</td>\n",
       "      <td>1.251202</td>\n",
       "      <td>0.278426</td>\n",
       "      <td>-0.034453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.014391</td>\n",
       "      <td>-1.474245</td>\n",
       "      <td>0.358902</td>\n",
       "      <td>-0.989069</td>\n",
       "      <td>-0.037079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.616004</td>\n",
       "      <td>0.188970</td>\n",
       "      <td>-0.762942</td>\n",
       "      <td>-0.912251</td>\n",
       "      <td>-0.038553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.556024</td>\n",
       "      <td>-0.129518</td>\n",
       "      <td>-0.010682</td>\n",
       "      <td>1.110620</td>\n",
       "      <td>-0.038497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.631226</td>\n",
       "      <td>0.825945</td>\n",
       "      <td>-0.302688</td>\n",
       "      <td>0.969787</td>\n",
       "      <td>-0.038317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.179821</td>\n",
       "      <td>-0.369715</td>\n",
       "      <td>0.304032</td>\n",
       "      <td>-0.038453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>-0.127194</td>\n",
       "      <td>-0.341844</td>\n",
       "      <td>-0.544061</td>\n",
       "      <td>0.803349</td>\n",
       "      <td>-0.038570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>-0.728807</td>\n",
       "      <td>1.746022</td>\n",
       "      <td>0.062624</td>\n",
       "      <td>0.790546</td>\n",
       "      <td>-0.038317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.700024</td>\n",
       "      <td>-0.164906</td>\n",
       "      <td>-0.049813</td>\n",
       "      <td>1.161832</td>\n",
       "      <td>-0.038384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.224357</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>0.022367</td>\n",
       "      <td>-0.038010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>-0.766407</td>\n",
       "      <td>-1.332695</td>\n",
       "      <td>0.313247</td>\n",
       "      <td>-1.181113</td>\n",
       "      <td>-0.037507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.436818</td>\n",
       "      <td>-1.615795</td>\n",
       "      <td>-0.251640</td>\n",
       "      <td>-1.181113</td>\n",
       "      <td>-0.038460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.211213</td>\n",
       "      <td>1.746022</td>\n",
       "      <td>-0.574939</td>\n",
       "      <td>0.700925</td>\n",
       "      <td>-0.038280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.191145</td>\n",
       "      <td>-0.451601</td>\n",
       "      <td>-0.310511</td>\n",
       "      <td>-0.038513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.173613</td>\n",
       "      <td>-1.651183</td>\n",
       "      <td>0.706725</td>\n",
       "      <td>-0.092860</td>\n",
       "      <td>-0.038488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.173613</td>\n",
       "      <td>-0.094131</td>\n",
       "      <td>0.384136</td>\n",
       "      <td>0.163200</td>\n",
       "      <td>-0.037571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-0.879210</td>\n",
       "      <td>0.932108</td>\n",
       "      <td>0.408337</td>\n",
       "      <td>0.700925</td>\n",
       "      <td>-0.038037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-0.277597</td>\n",
       "      <td>0.259745</td>\n",
       "      <td>-0.043543</td>\n",
       "      <td>-0.489752</td>\n",
       "      <td>-0.038459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-0.503202</td>\n",
       "      <td>1.356759</td>\n",
       "      <td>-0.629827</td>\n",
       "      <td>0.828955</td>\n",
       "      <td>-0.038427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>-1.593625</td>\n",
       "      <td>-0.731107</td>\n",
       "      <td>-0.579925</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>-0.038324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.737625</td>\n",
       "      <td>0.861333</td>\n",
       "      <td>1.654543</td>\n",
       "      <td>-0.208087</td>\n",
       "      <td>-0.037614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.098411</td>\n",
       "      <td>-1.332695</td>\n",
       "      <td>-0.818950</td>\n",
       "      <td>1.161832</td>\n",
       "      <td>-0.038387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>-0.804008</td>\n",
       "      <td>-1.297307</td>\n",
       "      <td>-0.655186</td>\n",
       "      <td>0.598501</td>\n",
       "      <td>-0.038280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>-0.879210</td>\n",
       "      <td>0.613620</td>\n",
       "      <td>-0.483028</td>\n",
       "      <td>0.406456</td>\n",
       "      <td>-0.038317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.341844</td>\n",
       "      <td>-0.326231</td>\n",
       "      <td>-1.219522</td>\n",
       "      <td>-0.037846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>-1.556024</td>\n",
       "      <td>0.790558</td>\n",
       "      <td>-0.480723</td>\n",
       "      <td>0.060776</td>\n",
       "      <td>-0.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.023209</td>\n",
       "      <td>1.002883</td>\n",
       "      <td>-0.090638</td>\n",
       "      <td>-1.245128</td>\n",
       "      <td>-0.037708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.624822</td>\n",
       "      <td>-0.695719</td>\n",
       "      <td>-0.397590</td>\n",
       "      <td>-1.219522</td>\n",
       "      <td>-0.037010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>-0.578403</td>\n",
       "      <td>-1.509633</td>\n",
       "      <td>-0.564775</td>\n",
       "      <td>0.713728</td>\n",
       "      <td>-0.037364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>1.000830</td>\n",
       "      <td>-0.094131</td>\n",
       "      <td>-0.313219</td>\n",
       "      <td>-0.118466</td>\n",
       "      <td>-0.038539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.662423</td>\n",
       "      <td>0.719783</td>\n",
       "      <td>0.300306</td>\n",
       "      <td>0.240017</td>\n",
       "      <td>-0.037860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.376838</td>\n",
       "      <td>0.365907</td>\n",
       "      <td>0.492254</td>\n",
       "      <td>0.611304</td>\n",
       "      <td>-0.038492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.352799</td>\n",
       "      <td>-1.615795</td>\n",
       "      <td>0.131503</td>\n",
       "      <td>0.700925</td>\n",
       "      <td>-0.037878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.104815</td>\n",
       "      <td>0.118194</td>\n",
       "      <td>-0.420944</td>\n",
       "      <td>0.880166</td>\n",
       "      <td>-0.038197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.489641</td>\n",
       "      <td>1.569084</td>\n",
       "      <td>-0.407745</td>\n",
       "      <td>0.816152</td>\n",
       "      <td>-0.038190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.715245</td>\n",
       "      <td>0.224357</td>\n",
       "      <td>-0.136388</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>-0.038315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     col_inexistente1      col2       col3  col_outliers  col_outliers2  \\\n",
       "0            0.399217  0.082807   0.442819     -0.694600      -0.038365   \n",
       "1           -0.653605  0.861333  -0.323390     -0.118466      -0.038278   \n",
       "2            1.226435 -0.766494  -0.484752     -0.464146      -0.038343   \n",
       "3           -0.540803 -1.191145  -0.375028     -1.129901      -0.038405   \n",
       "4           -0.616004 -0.766494  -0.516874      0.777743      -0.037257   \n",
       "5            1.226435 -1.615795   0.088218      0.598501      -0.038353   \n",
       "6            0.324016 -0.660332  -0.749767      0.944181      -0.038229   \n",
       "7           -0.540803 -1.049595  10.836735      1.136226      -0.038215   \n",
       "8           -0.428000  1.639859   0.543972      0.636910      -0.038210   \n",
       "9            0.000000  0.118194   0.464862      0.739334      -0.038278   \n",
       "10           0.000000  1.746022  -0.041517      1.200241      -0.037373   \n",
       "11           1.038431 -1.155757  -0.404065     -1.257931      -0.038157   \n",
       "12          -0.352799 -0.377231  -0.578128     -1.270734      -0.038491   \n",
       "13          -0.578403 -0.978820  -0.369566     -1.257931      -0.038441   \n",
       "14           1.076032  0.684395  -0.020709     -0.438540      -0.038455   \n",
       "15          -0.390399  1.533696  -0.621890     -0.195284      -0.038343   \n",
       "16           0.000000  0.012032  -0.594129      0.700925      -0.032547   \n",
       "17           0.000000  0.825945  -0.659086      1.200241      -0.038368   \n",
       "18          -1.744028 -1.049595  -0.557416     -1.270734      -0.037935   \n",
       "19           0.888028 -0.872657  -0.139629      0.176003      -0.038333   \n",
       "20          -0.352799 -1.191145  -0.657547     -0.758615      -0.038463   \n",
       "21           0.136012 -1.615795  -0.314097      0.777743      -0.038579   \n",
       "22          -1.292819  1.427534   0.149977     -0.438540      -0.038486   \n",
       "23           0.000000  1.250596   1.269758     -0.668994      -0.037665   \n",
       "24           1.790447  0.436682   1.251202      0.278426      -0.034453   \n",
       "25          -0.014391 -1.474245   0.358902     -0.989069      -0.037079   \n",
       "26          -0.616004  0.188970  -0.762942     -0.912251      -0.038553   \n",
       "27          -1.556024 -0.129518  -0.010682      1.110620      -0.038497   \n",
       "28          -1.631226  0.825945  -0.302688      0.969787      -0.038317   \n",
       "29           0.000000  1.179821  -0.369715      0.304032      -0.038453   \n",
       "..                ...       ...        ...           ...            ...   \n",
       "970         -0.127194 -0.341844  -0.544061      0.803349      -0.038570   \n",
       "971         -0.728807  1.746022   0.062624      0.790546      -0.038317   \n",
       "972          0.700024 -0.164906  -0.049813      1.161832      -0.038384   \n",
       "973          0.850427  0.224357  -0.344081      0.022367      -0.038010   \n",
       "974         -0.766407 -1.332695   0.313247     -1.181113      -0.037507   \n",
       "975          0.436818 -1.615795  -0.251640     -1.181113      -0.038460   \n",
       "976          0.211213  1.746022  -0.574939      0.700925      -0.038280   \n",
       "977          0.000000 -1.191145  -0.451601     -0.310511      -0.038513   \n",
       "978          0.173613 -1.651183   0.706725     -0.092860      -0.038488   \n",
       "979          0.173613 -0.094131   0.384136      0.163200      -0.037571   \n",
       "980         -0.879210  0.932108   0.408337      0.700925      -0.038037   \n",
       "981         -0.277597  0.259745  -0.043543     -0.489752      -0.038459   \n",
       "982         -0.503202  1.356759  -0.629827      0.828955      -0.038427   \n",
       "983         -1.593625 -0.731107  -0.579925     -0.259299      -0.038324   \n",
       "984          0.737625  0.861333   1.654543     -0.208087      -0.037614   \n",
       "985          0.098411 -1.332695  -0.818950      1.161832      -0.038387   \n",
       "986         -0.804008 -1.297307  -0.655186      0.598501      -0.038280   \n",
       "987         -0.879210  0.613620  -0.483028      0.406456      -0.038317   \n",
       "988          0.000000 -0.341844  -0.326231     -1.219522      -0.037846   \n",
       "989         -1.556024  0.790558  -0.480723      0.060776      -0.038462   \n",
       "990          0.023209  1.002883  -0.090638     -1.245128      -0.037708   \n",
       "991          0.624822 -0.695719  -0.397590     -1.219522      -0.037010   \n",
       "992         -0.578403 -1.509633  -0.564775      0.713728      -0.037364   \n",
       "993          1.000830 -0.094131  -0.313219     -0.118466      -0.038539   \n",
       "994          0.662423  0.719783   0.300306      0.240017      -0.037860   \n",
       "995          1.376838  0.365907   0.492254      0.611304      -0.038492   \n",
       "996         -0.352799 -1.615795   0.131503      0.700925      -0.037878   \n",
       "997         -1.104815  0.118194  -0.420944      0.880166      -0.038197   \n",
       "998          1.489641  1.569084  -0.407745      0.816152      -0.038190   \n",
       "999          1.715245  0.224357  -0.136388      0.726531      -0.038315   \n",
       "\n",
       "     elefante  gato  perro  ratón  acordarme     ...           vaca    veinte  \\\n",
       "0         0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.204745   \n",
       "1         1.0   0.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "2         0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "3         0.0   1.0    0.0    0.0   0.000000     ...       0.194272  0.000000   \n",
       "4         0.0   1.0    0.0    0.0   0.000000     ...       0.000000  0.204745   \n",
       "5         0.0   0.0    1.0    0.0   0.197887     ...       0.000000  0.000000   \n",
       "6         0.0   0.0    1.0    0.0   0.197887     ...       0.000000  0.000000   \n",
       "7         0.0   0.0    1.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "8         1.0   0.0    0.0    0.0   0.000000     ...       0.000000  0.204745   \n",
       "9         1.0   0.0    0.0    0.0   0.197887     ...       0.000000  0.000000   \n",
       "10        0.0   0.0    1.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "11        1.0   0.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "12        0.0   1.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "13        0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "14        0.0   1.0    0.0    0.0   0.197887     ...       0.000000  0.000000   \n",
       "15        0.0   0.0    0.0    1.0   0.197887     ...       0.000000  0.000000   \n",
       "16        1.0   0.0    0.0    0.0   0.197887     ...       0.000000  0.000000   \n",
       "17        0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "18        0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "19        1.0   0.0    0.0    0.0   0.000000     ...       0.194272  0.000000   \n",
       "20        0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.204745   \n",
       "21        0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "22        0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "23        0.0   1.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "24        0.0   1.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "25        0.0   0.0    0.0    1.0   0.197887     ...       0.000000  0.000000   \n",
       "26        0.0   1.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "27        1.0   0.0    0.0    0.0   0.197887     ...       0.000000  0.000000   \n",
       "28        0.0   1.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "29        1.0   0.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "..        ...   ...    ...    ...        ...     ...            ...       ...   \n",
       "970       0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "971       0.0   1.0    0.0    0.0   0.197887     ...       0.000000  0.000000   \n",
       "972       1.0   0.0    0.0    0.0   0.197887     ...       0.000000  0.000000   \n",
       "973       0.0   0.0    1.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "974       0.0   0.0    1.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "975       1.0   0.0    0.0    0.0   0.000000     ...       0.000000  0.204745   \n",
       "976       0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "977       0.0   0.0    1.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "978       1.0   0.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "979       0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "980       0.0   1.0    0.0    0.0   0.000000     ...       0.000000  0.204745   \n",
       "981       0.0   0.0    1.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "982       0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.204745   \n",
       "983       0.0   1.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "984       0.0   1.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "985       0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "986       0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "987       0.0   1.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "988       0.0   0.0    1.0    0.0   0.000000     ...       0.000000  0.204745   \n",
       "989       0.0   0.0    1.0    0.0   0.000000     ...       0.194272  0.000000   \n",
       "990       0.0   0.0    1.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "991       1.0   0.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "992       0.0   1.0    0.0    0.0   0.197887     ...       0.000000  0.000000   \n",
       "993       0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.000000   \n",
       "994       0.0   0.0    0.0    1.0   0.197887     ...       0.000000  0.000000   \n",
       "995       1.0   0.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "996       0.0   0.0    0.0    1.0   0.000000     ...       0.000000  0.204745   \n",
       "997       1.0   0.0    0.0    0.0   0.000000     ...       0.000000  0.000000   \n",
       "998       1.0   0.0    0.0    0.0   0.197887     ...       0.000000  0.000000   \n",
       "999       1.0   0.0    0.0    0.0   0.000000     ...       0.000000  0.204745   \n",
       "\n",
       "      velarte   vellori   velludo    verdad  verosímiles   viernes     vivía  \\\n",
       "0    0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "1    0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "2    0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "3    0.000000  0.000000  0.000000  0.000000     0.000000  0.194272  0.000000   \n",
       "4    0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "5    0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "6    0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "7    0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "8    0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "9    0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "10   0.000000  0.000000  0.000000  0.137571     0.137571  0.000000  0.000000   \n",
       "11   0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "12   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "13   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "14   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "15   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "16   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "17   0.000000  0.000000  0.000000  0.137571     0.137571  0.000000  0.000000   \n",
       "18   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "19   0.000000  0.000000  0.000000  0.000000     0.000000  0.194272  0.000000   \n",
       "20   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "21   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "22   0.000000  0.000000  0.000000  0.137571     0.137571  0.000000  0.000000   \n",
       "23   0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "24   0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "25   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "26   0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "27   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "28   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "29   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "..        ...       ...       ...       ...          ...       ...       ...   \n",
       "970  0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "971  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "972  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "973  0.000000  0.000000  0.000000  0.137571     0.137571  0.000000  0.000000   \n",
       "974  0.000000  0.000000  0.000000  0.137571     0.137571  0.000000  0.000000   \n",
       "975  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "976  0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "977  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "978  0.000000  0.000000  0.000000  0.137571     0.137571  0.000000  0.000000   \n",
       "979  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "980  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "981  0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "982  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "983  0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "984  0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "985  0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "986  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "987  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "988  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "989  0.000000  0.000000  0.000000  0.000000     0.000000  0.194272  0.000000   \n",
       "990  0.000000  0.000000  0.000000  0.137571     0.137571  0.000000  0.000000   \n",
       "991  0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "992  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "993  0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "994  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "995  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "996  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "997  0.181842  0.181842  0.181842  0.000000     0.000000  0.000000  0.000000   \n",
       "998  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.197887   \n",
       "999  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "\n",
       "     col_ordinal  \n",
       "0              2  \n",
       "1              4  \n",
       "2              3  \n",
       "3              1  \n",
       "4              0  \n",
       "5              4  \n",
       "6              0  \n",
       "7              4  \n",
       "8              0  \n",
       "9              2  \n",
       "10             4  \n",
       "11             1  \n",
       "12             4  \n",
       "13             2  \n",
       "14             3  \n",
       "15             1  \n",
       "16             0  \n",
       "17             1  \n",
       "18             4  \n",
       "19             2  \n",
       "20             0  \n",
       "21             0  \n",
       "22             3  \n",
       "23             4  \n",
       "24             2  \n",
       "25             1  \n",
       "26             1  \n",
       "27             0  \n",
       "28             0  \n",
       "29             0  \n",
       "..           ...  \n",
       "970            4  \n",
       "971            1  \n",
       "972            1  \n",
       "973            4  \n",
       "974            1  \n",
       "975            0  \n",
       "976            4  \n",
       "977            0  \n",
       "978            2  \n",
       "979            2  \n",
       "980            1  \n",
       "981            4  \n",
       "982            1  \n",
       "983            1  \n",
       "984            4  \n",
       "985            0  \n",
       "986            2  \n",
       "987            3  \n",
       "988            2  \n",
       "989            0  \n",
       "990            0  \n",
       "991            0  \n",
       "992            0  \n",
       "993            3  \n",
       "994            2  \n",
       "995            3  \n",
       "996            2  \n",
       "997            4  \n",
       "998            0  \n",
       "999            4  \n",
       "\n",
       "[1000 rows x 144 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
